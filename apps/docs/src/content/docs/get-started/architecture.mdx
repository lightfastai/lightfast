---
title: Architecture
description: High-level technical overview of how Lightfast works
---

# Architecture

Lightfast is memory built for teams—a searchable knowledge base that indexes your organization's content and makes it instantly findable through semantic search. This guide explains the system architecture, core components, and key design decisions.

## System Overview

Lightfast connects to your repositories and tools (GitHub, Linear, Notion, Slack) to capture your team's knowledge. Content flows through an indexing pipeline that extracts text, generates embeddings, builds a knowledge graph, and makes everything searchable via four simple API endpoints.

**Architecture layers:**

1. **Source Integration** — OAuth connections to GitHub, webhooks for real-time updates
2. **Indexing Pipeline** — Extract, chunk, embed, and organize content
3. **Storage Layer** — Metadata (PlanetScale), vectors (Pinecone), bodies (S3), cache (Redis)
4. **Search Engine** — Hybrid retrieval, reranking, citation generation
5. **API Layer** — Four endpoints: `/search`, `/contents`, `/similar`, `/answer`

All components are workspace-isolated with complete tenant separation at every layer.

## Core Components

### Indexing Pipeline

When content is added or updated, Lightfast:

1. **Extracts content** — Pull requests, issues, docs, discussions from source systems
2. **Chunks documents** — Break long files into semantic sections
3. **Generates embeddings** — Create multi-view vectors (title, snippet, body, summary)
4. **Builds graph** — Extract entities (people, repos) and relationships (ownership, dependencies)
5. **Stores results** — Metadata in database, vectors in Pinecone, bodies in S3

**Indexing triggers:**
- Initial repository connection (full index)
- Git pushes (incremental update via webhooks)
- PR/issue events (real-time updates)
- Scheduled sync (daily catchup for missed events)

### Storage Layer

**PlanetScale (MySQL)** — Relational metadata
- Document metadata (titles, URLs, timestamps)
- Graph entities and relationships
- User profiles and workspace config
- Chunk mappings and observation records

**Pinecone** — Vector embeddings
- Multi-view embeddings per document
- Namespace isolation per workspace
- Metadata filtering for permissions
- Fast approximate nearest neighbor search

**S3** — Document bodies
- Full document content for retrieval
- Chunked text for citation snippets
- Compressed and encrypted at rest

**Redis** — Caching and queuing
- Query result caching (TTL: 5-15 minutes)
- Embedding cache (deduplication)
- Background job queues (indexing, reranking)
- Rate limiting counters

### Search Engine

**Query processing:**

1. **Intent classification** — Determine query type (factual, exploratory, complex)
2. **Embedding generation** — Convert query to vector
3. **Hybrid retrieval** — Dense (vector) + lexical (keyword) + graph (relationships)
4. **Permission filtering** — Remove inaccessible results based on user's GitHub permissions
5. **Reranking** — Cross-encoder model refines top 50-100 candidates
6. **Citation selection** — Choose diverse, relevant sources for answers

**Ranking signals:**
- Semantic similarity (vector distance)
- Lexical matching (keyword overlap)
- Recency (time decay based on workspace calibration)
- Importance (stars, reactions, comments)
- Graph relationships (ownership, dependencies)
- Profile similarity (personalization)

### API Layer

Four endpoints power all functionality:

**`POST /v1/search`** — Find relevant documents
- Input: query string, filters (store, type, date range)
- Output: ranked results with snippets and metadata
- Use case: Search interface, discovery, exploration

**`POST /v1/contents`** — Retrieve full documents
- Input: document IDs
- Output: Complete content, metadata, relationships
- Use case: Full-text display, citation details

**`POST /v1/similar`** — Find related content
- Input: document ID or text snippet
- Output: Semantically similar documents
- Use case: "More like this", related work discovery

**`POST /v1/answer`** — Get synthesized answers with citations
- Input: question string
- Output: Answer text + citations + rationale
- Use case: AI chat, Q&A interfaces, agent tools

All endpoints support streaming for real-time results and include permission checks.

## Data Flow

### Indexing Flow

```
GitHub → Webhook → Queue → Extractor → Chunker → Embedder → Storage
                                                              ↓
                                                    Graph Builder → Database
```

1. GitHub event (push, PR, issue) triggers webhook
2. Event queued in Redis for processing
3. Extractor pulls content from GitHub API
4. Chunker splits long documents semantically
5. Embedder generates multi-view vectors
6. Graph builder extracts entities/relationships
7. Everything stored in respective databases

### Query Flow

```
API Request → Auth → Intent → Retrieval → Filter → Rerank → Response
                       ↓         ↓          ↓         ↓
                   Classify   Hybrid    Permissions Cross-encoder
```

1. API request authenticated (API key or OAuth)
2. Query intent classified (knowledge/neural/hybrid mode)
3. Hybrid retrieval from Pinecone + database
4. Permission filtering based on user's GitHub access
5. Cross-encoder reranking for precision
6. Results formatted and returned (with citations for `/answer`)

## Key Design Decisions

### Multi-View Embeddings

**Why:** Different search types need different representations. High-level queries match titles; specific questions need body content.

**How:** Each document embedded 4 ways (title, snippet, body, summary). Query router selects views based on intent.

**Benefit:** Same document findable via broad topics or specific details.

### Short-Hop Graph Reasoning

**Why:** Long graph chains lead to speculation and black-box answers. We prioritize explainability.

**How:** Limit graph traversals to 1-2 hops with explicit relationships.

**Benefit:** Every result is grounded in evidence. Users can verify reasoning paths.

### Workspace Isolation

**Why:** Enterprise security and privacy require complete tenant separation.

**How:** Separate database tables, namespaced vectors, isolated caches, independent calibration.

**Benefit:** Zero cross-workspace leakage. Each team's data and usage patterns stay private.

### Continuous Calibration

**Why:** One-size-fits-all ranking doesn't work. Fast-moving teams value recency; stable projects value comprehensiveness.

**How:** Per-workspace ranking weights, decay factors, and thresholds tune based on usage.

**Benefit:** Search quality improves over time for your specific team and content.

## Integration Points

**GitHub:**
- OAuth for authentication and permissions
- Webhooks for real-time updates
- REST API for content fetching
- GraphQL for efficient bulk queries

**Pinecone:**
- Namespace per workspace
- Metadata filtering for permissions
- Hybrid search (dense + sparse)
- Pod-based isolation

**PlanetScale:**
- Serverless MySQL with auto-scaling
- Connection pooling via PlanetScale Proxy
- Regional replicas for low latency
- Branching for schema migrations

**S3:**
- Encrypted storage for document bodies
- Presigned URLs for secure access
- Lifecycle policies for archival
- Cross-region replication (enterprise)

**Redis (Upstash):**
- Serverless with per-request pricing
- Geo-replication for low latency
- TLS encryption in transit
- Persistence for job queues

## Performance Characteristics

**Indexing:**
- Initial index: 1000-5000 docs/minute
- Incremental updates: Under 30 seconds from push to searchable
- Full re-index: Parallel processing, typically 5-10 minutes for 50k docs

**Query latency:**
- `/search`: p50 ~200ms, p99 ~800ms
- `/answer`: p50 ~1.5s, p99 ~4s (includes LLM synthesis)
- `/contents`: p50 ~50ms (cached), ~200ms (uncached)
- `/similar`: p50 ~150ms, p99 ~600ms

**Scalability:**
- Workspace limit: 10M documents (10M+ available for enterprise)
- Concurrent queries: Auto-scaling handles 1000s of QPS
- Embedding throughput: 10k docs/minute with batch processing

## Next Steps

Now that you understand the architecture, explore individual features and API usage:

- **<NextLink href="/docs/features/search">Search & Retrieval</NextLink>** — How semantic search works
- **<NextLink href="/docs/features/memory">Memory Organization</NextLink>** — Chunks, observations, summaries, profiles
- **<NextLink href="/docs/features/relationships">Graph Relationships</NextLink>** — Entity and content connections
- **<NextLink href="/docs/features/citations">Citations & Sources</NextLink>** — Answer verification
- **<NextLink href="/docs/features/quality">Quality & Evaluation</NextLink>** — Metrics and calibration
- **<NextLink href="/docs/features/security">Privacy & Security</NextLink>** — Isolation and compliance
- **<NextLink href="/api/overview">API Reference</NextLink>** — Endpoint documentation
