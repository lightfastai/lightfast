<!DOCTYPE html>
<html lang="en" class="dark-mode">
<head>
<meta name="robots" content="index, follow">

    <title>Knowledge Graph For RAG: Step-by-Step Tutorial</title>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    
    <link rel="preload" as="style" href="/blog/assets/built/screen.css?v=259661198b" />
    <link rel="preload" as="script" href="/blog/assets/built/casper.js?v=259661198b" />

    <link rel="stylesheet" type="text/css" href="/blog/assets/built/screen.css?v=259661198b" />

    <link rel="icon" href="https://supermemory.ai/blog/content/images/size/w256h256/2025/06/SuperM_LinkedIn-Github-Twitter_ProfilePicture--1--1.png" type="image/png">
    <link rel="canonical" href="https://supermemory.ai/blog/knowledge-graph-for-rag-step-by-step-tutorial/">
    <meta name="referrer" content="no-referrer-when-downgrade">
    
    <meta property="og:site_name" content="supermemory - Blog">
    <meta property="og:type" content="article">
    <meta property="og:title" content="Knowledge Graph For RAG: Step-by-Step Tutorial">
    <meta property="og:description" content="If you’ve ever built a retrieval-augmented generation (RAG) system using embeddings and vector databases, you already know the drill: you turn your data into vectors, stuff them into a store like FAISS, and let your model retrieve similar chunks during inference.

And it works, until it doesn’t.


Why">
    <meta property="og:url" content="https://supermemory.ai/blog/knowledge-graph-for-rag-step-by-step-tutorial/">
    <meta property="og:image" content="https://supermemory.ai/blog/content/images/2025/07/11.webp">
    <meta property="article:published_time" content="2025-07-12T07:56:27.000Z">
    <meta property="article:modified_time" content="2025-07-12T07:56:27.000Z">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Knowledge Graph For RAG: Step-by-Step Tutorial">
    <meta name="twitter:description" content="If you’ve ever built a retrieval-augmented generation (RAG) system using embeddings and vector databases, you already know the drill: you turn your data into vectors, stuff them into a store like FAISS, and let your model retrieve similar chunks during inference.

And it works, until it doesn’t.


Why">
    <meta name="twitter:url" content="https://supermemory.ai/blog/knowledge-graph-for-rag-step-by-step-tutorial/">
    <meta name="twitter:image" content="https://supermemory.ai/blog/content/images/2025/07/11.webp">
    <meta name="twitter:label1" content="Written by">
    <meta name="twitter:data1" content="Naman Bansal">
    <meta name="twitter:site" content="@supermemoryai">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="675">
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "supermemory - Blog",
        "url": "https://supermemory.ai/blog/",
        "logo": {
            "@type": "ImageObject",
            "url": "https://supermemory.ai/blog/content/images/2025/06/Frame-2147223248.svg"
        }
    },
    "author": {
        "@type": "Person",
        "name": "Naman Bansal",
        "image": {
            "@type": "ImageObject",
            "url": "https://www.gravatar.com/avatar/1b424ffbaa308b371e62efa5919dfe3d?s=250&r=x&d=mp",
            "width": 250,
            "height": 250
        },
        "url": "https://supermemory.ai/blog/author/naman/",
        "sameAs": []
    },
    "headline": "Knowledge Graph For RAG: Step-by-Step Tutorial",
    "url": "https://supermemory.ai/blog/knowledge-graph-for-rag-step-by-step-tutorial/",
    "datePublished": "2025-07-12T07:56:27.000Z",
    "dateModified": "2025-07-12T07:56:27.000Z",
    "image": {
        "@type": "ImageObject",
        "url": "https://supermemory.ai/blog/content/images/2025/07/11.webp",
        "width": 1200,
        "height": 675
    },
    "description": "If you’ve ever built a retrieval-augmented generation (RAG) system using embeddings and vector databases, you already know the drill: you turn your data into vectors, stuff them into a store like FAISS, and let your model retrieve similar chunks during inference.\n\nAnd it works, until it doesn’t.\n\n\nWhy Vector Search Alone Falls Short\n\nEmbeddings are great at catching semantic similarity. But what they don’t give you is structure. They don’t know that “Supplier A ships to Germany” or that “Product",
    "mainEntityOfPage": "https://supermemory.ai/blog/knowledge-graph-for-rag-step-by-step-tutorial/"
}
    </script>

    <meta name="generator" content="Ghost 5.130">
    <link rel="alternate" type="application/rss+xml" title="supermemory - Blog" href="https://supermemory.ai/blog/rss/">
    
    <script defer src="https://cdn.jsdelivr.net/ghost/sodo-search@~1.8/umd/sodo-search.min.js" data-key="d2a094c14f6148bdbd8ad26051" data-styles="https://cdn.jsdelivr.net/ghost/sodo-search@~1.8/umd/main.css" data-sodo-search="https://supermemory.ai/blog/" data-locale="en" crossorigin="anonymous"></script>
    
    <link href="https://supermemory.ai/blog/webmentions/receive/" rel="webmention">
    <script defer src="/blog/public/cards.min.js?v=259661198b"></script><style>:root {--ghost-accent-color: #3d49d8;}</style>
    <link rel="stylesheet" type="text/css" href="/blog/public/cards.min.css?v=259661198b">
    <style>
  .gh-footer-copyright {
    display: none !important;
}
a[href*="ghost.org"] {
    display: none !important;
}
::selection {
  background: #267BF1;
  color: #FFF;
}
</style>

<script>
document.addEventListener('DOMContentLoaded', function() {
    // Find all navigation logo links
    const logoLinks = document.querySelectorAll('.gh-navigation-logo');
    
    logoLinks.forEach(function(link) {
        // Change the href to point to main site
        link.href = 'https://supermemory.ai';
    });
});

  // Ensure all pages point to the main domain version
  const canonical = document.querySelector('link[rel="canonical"]');
  if (canonical && canonical.href.includes('blog.supermemory.ai')) {
    canonical.href = canonical.href.replace('blog.supermemory.ai', 'supermemory.ai/blog');
  }

if (typeof window !== 'undefined') {
  // Client-side check
  const hostname = window.location.hostname;
  const userAgent = navigator.userAgent;
  const isCloudflareWorker = userAgent.includes('Cloudflare-Workers');
  const isGhostAdmin = window.location.pathname.startsWith('/ghost');
  
  if (hostname === 'blog.supermemory.ai' && !isCloudflareWorker && !isGhostAdmin) {
    window.location.replace('https://supermemory.ai/blog' + window.location.pathname.replace('/blog', '') + window.location.search);
  }
}
</script>

<script>
    !function(t,e){var o,n,p,r;e.__SV||(window.posthog && window.posthog.__loaded)||(window.posthog=e,e._i=[],e.init=function(i,s,a){function g(t,e){var o=e.split(".");2==o.length&&(t=t[o[0]],e=o[1]),t[e]=function(){t.push([e].concat(Array.prototype.slice.call(arguments,0)))}}(p=t.createElement("script")).type="text/javascript",p.crossOrigin="anonymous",p.async=!0,p.src=s.api_host.replace(".i.posthog.com","-assets.i.posthog.com")+"/static/array.js",(r=t.getElementsByTagName("script")[0]).parentNode.insertBefore(p,r);var u=e;for(void 0!==a?u=e[a]=[]:a="posthog",u.people=u.people||[],u.toString=function(t){var e="posthog";return"posthog"!==a&&(e+="."+a),t||(e+=" (stub)"),e},u.people.toString=function(){return u.toString(1)+".people (stub)"},o="init Ce js Ls Te Fs Ds capture Ye calculateEventProperties zs register register_once register_for_session unregister unregister_for_session Ws getFeatureFlag getFeatureFlagPayload isFeatureEnabled reloadFeatureFlags updateEarlyAccessFeatureEnrollment getEarlyAccessFeatures on onFeatureFlags onSurveysLoaded onSessionId getSurveys getActiveMatchingSurveys renderSurvey displaySurvey canRenderSurvey canRenderSurveyAsync identify setPersonProperties group resetGroups setPersonPropertiesForFlags resetPersonPropertiesForFlags setGroupPropertiesForFlags resetGroupPropertiesForFlags reset get_distinct_id getGroups get_session_id get_session_replay_url alias set_config startSessionRecording stopSessionRecording sessionRecordingStarted captureException loadToolbar get_property getSessionProperty Bs Us createPersonProfile Hs Ms Gs opt_in_capturing opt_out_capturing has_opted_in_capturing has_opted_out_capturing get_explicit_consent_status is_capturing clear_opt_in_out_capturing Ns debug L qs getPageViewId captureTraceFeedback captureTraceMetric".split(" "),n=0;n<o.length;n++)g(u,o[n]);e._i.push([i,s,a])},e.__SV=1)}(document,window.posthog||[]);
    posthog.init('phc_9wkqAZtZYAUCNwvus0hYqcZbw5EBEX2s3QXjZoNdUNS', {
        api_host: 'https://us.i.posthog.com',
        defaults: '2025-05-24',
        person_profiles: 'identified_only', // or 'always' to create profiles for anonymous users as well
    })
</script>
    <link rel="preconnect" href="https://fonts.bunny.net"><link rel="stylesheet" href="https://fonts.bunny.net/css?family=space-grotesk:700|space-mono:400,700"><style>:root {--gh-font-heading: Space Grotesk;--gh-font-body: Space Mono;}</style>

</head>
<body class="post-template gh-font-heading-space-grotesk gh-font-body-space-mono is-head-left-logo">
<div class="viewport">

    <header id="gh-head" class="gh-head outer">
        <div class="gh-head-inner inner">
            <div class="gh-head-brand">
                <a class="gh-head-logo" href="https://supermemory.ai/blog">
                        <img src="https://supermemory.ai/blog/content/images/2025/06/Frame-2147223248.svg" alt="supermemory - Blog">
                </a>
                <button class="gh-search gh-icon-btn" aria-label="Search this site" data-ghost-search><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2" width="20" height="20"><path stroke-linecap="round" stroke-linejoin="round" d="M21 21l-6-6m2-5a7 7 0 11-14 0 7 7 0 0114 0z"></path></svg></button>
                <button class="gh-burger" aria-label="Main Menu"></button>
            </div>

            <nav class="gh-head-menu">
                <ul class="nav">
    <li class="nav-home"><a href="https://supermemory.ai">Home</a></li>
    <li class="nav-blogs"><a href="https://supermemory.ai/blog">Blogs</a></li>
    <li class="nav-updates"><a href="https://docs.supermemory.ai/changelog/overview">Updates</a></li>
    <li class="nav-docs"><a href="https://docs.supermemory.ai">Docs</a></li>
</ul>

            </nav>

            <div class="gh-head-actions">
                        <button class="gh-search gh-icon-btn" aria-label="Search this site" data-ghost-search><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2" width="20" height="20"><path stroke-linecap="round" stroke-linejoin="round" d="M21 21l-6-6m2-5a7 7 0 11-14 0 7 7 0 0114 0z"></path></svg></button>
            </div>
        </div>
    </header>

    <div class="site-content">
        



<main id="site-main" class="site-main">
<article class="article post ">

    <header class="article-header gh-canvas">

        <div class="article-tag post-card-tags">
        </div>

        <h1 class="article-title">Knowledge Graph For RAG: Step-by-Step Tutorial</h1>


        <div class="article-byline">
        <section class="article-byline-content">

            <ul class="author-list instapaper_ignore">
                <li class="author-list-item">
                    <a href="/blog/author/naman/" class="author-avatar" aria-label="Read more of Naman Bansal">
                        <img class="author-profile-image" src="https://www.gravatar.com/avatar/1b424ffbaa308b371e62efa5919dfe3d?s&#x3D;250&amp;r&#x3D;x&amp;d&#x3D;mp" alt="Naman Bansal" />
                    </a>
                </li>
            </ul>

            <div class="article-byline-meta">
                <h4 class="author-name"><a href="/blog/author/naman/">Naman Bansal</a></h4>
                <div class="byline-meta-content">
                    <time class="byline-meta-date" datetime="2025-07-12">12 Jul 2025</time>
                        <span class="byline-reading-time"><span class="bull">&bull;</span> 12 min read</span>
                </div>
            </div>

        </section>
        </div>

            <figure class="article-image">
                <img
                    srcset="/content/images/size/w300/2025/07/11.webp 300w,
                            /content/images/size/w600/2025/07/11.webp 600w,
                            /content/images/size/w1000/2025/07/11.webp 1000w,
                            /content/images/size/w2000/2025/07/11.webp 2000w"
                    sizes="(min-width: 1400px) 1400px, 92vw"
                    src="/blog/content/images/size/w2000/2025/07/11.webp"
                    alt="Knowledge Graph For RAG: Step-by-Step Tutorial"
                />
            </figure>

    </header>

    <section class="gh-content gh-canvas">
        <p>If you’ve ever built a retrieval-augmented generation (RAG) system using embeddings and vector databases, you already know the drill: you turn your data into vectors, stuff them into a store like <a href="https://github.com/facebookresearch/faiss?ref=blog.supermemory.ai">FAISS</a>, and let your model retrieve similar chunks during inference.</p><p>And it works, until it doesn’t.</p><h3 id="why-vector-search-alone-falls-short">Why Vector Search Alone Falls Short</h3><p>Embeddings are great at catching semantic similarity. But what they don’t give you is structure. They don’t know that “Supplier A ships to Germany” or that “Product X requires a temperature-controlled warehouse.” They don’t understand relationships.</p><p>This becomes a real problem when:</p><ul><li>You need to enforce business logic<br>(e.g., “<em>Only show suppliers who are certified and in the same region</em>”)</li><li>You want to combine structured facts with natural text<br>(e.g., “<em>Summarize my top 5 suppliers in Europe for Product X</em>”)</li><li>You need explainability<br>(e.g., “<em>Why was this supplier recommended?</em>”)</li></ul><p>In short, vector search is like a very smart blur, which can be really helpful, but sometimes too vague.</p><h3 id="why-knowledge-graphs-are-catching-on">Why Knowledge Graphs Are Catching On</h3><p>That’s where knowledge graphs come in. Unlike vectors, graphs give you explicit relationships between entities. A product has a supplier. A supplier serves a location. A warehouse stores certain categories. And once that structure exists, querying becomes way more powerful and intuitive.</p><p>Here’s what makes knowledge graphs so useful in AI-powered apps:</p><ul><li><strong>Structured retrieval</strong>: You can write precise queries instead of relying on fuzzy matches.</li><li><strong>Explainability</strong>: You can show exactly why a result was retrieved.</li><li><strong>Domain alignment</strong>: Graphs reflect real-world relationships, just like your business rules do.</li></ul><figure class="kg-card kg-image-card"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXebTSWwC1IrgIU8dkccq9lAUPrt-S7eaTz12oAiyTt4jLmytGTuC8HgbpI_pf5lvWnNLLxYurrIQA_RnznCaNobLpEvkW9_Y3vAUI9IScE44qaBv50XiE_bt5Aho9qoEB9lUI1duw?key=lqZSFvuWmXmvGZnyQ5f1lQ" class="kg-image" alt="Vector Search vs Knowledge Graphs" loading="lazy" width="1024" height="1024"></figure><p>By the end of this article, you’ll build a working question-answering app that combines knowledge graphs with language models. Specifically:</p><ul><li>You’ll load supply chain data (product catalogs, suppliers, purchase orders)</li><li>Convert unstructured descriptions into structured relationships</li><li>Build a knowledge graph using <a href="https://neo4j.com/?ref=blog.supermemory.ai">Neo4j</a></li><li>Query the graph with user questions like “Which suppliers in Europe provide Product X?”</li><li>Generate natural-language answers based on retrieved graph data</li></ul><p>This is a very interesting real-world implementation of knowledge graph-based RAG.</p><h2 id="how-knowledge-graphs-work">How Knowledge Graphs Work</h2><p>Working with vector search, you already know that you take some text, embed it into a vector, and then look for other vectors that are close. The moment you need to reason over structured facts, relationships, or apply logic like “filter by supplier region,” vector search starts to feel like duct tape.</p><p>That’s where knowledge graphs step in.</p><p>A knowledge graph (KG) is a structured representation of facts. Instead of storing data as documents or raw text, it organizes the world as entities (like “<strong>Supplier A</strong>” or “<strong>Product X</strong>”) and relationships (like “supplies” or “located_in”) between them.</p><h3 id="the-building-blocks-of-a-knowledge-graph">The Building Blocks of a Knowledge Graph</h3><p>At the core, a KG is just a set of triples:</p><p><strong>(Entity A) — [Relation] → (Entity B)</strong></p><p>For example:<br><strong>(Supplier A) — [supplies] → (Product X)<br>(Supplier A) — [located_in] → (Germany)</strong></p><p>These triples are stored as nodes and edges, which together form a graph. Each node represents a unique concept or object, while each edge defines how two nodes are connected.</p><figure class="kg-card kg-image-card"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXeAnMTCZSXUR_Viin6XZBsfnsZMCbzlwCKdHeFW-KZ39Ee07B-WO78aIpwJ11yoE0CMvNtc7cMR6NdOXumcD2A3kPoCm_djE158Dwbw9VErtbolJ6xcUhCh1IK-wON1LvcjdHEJqg?key=lqZSFvuWmXmvGZnyQ5f1lQ" class="kg-image" alt="Anatomy of a Knowledge Graph" loading="lazy" width="1024" height="1024"></figure><p>Once you have this graph, retrieval becomes more than just blurry similarity. You can follow paths, apply constraints, and answer precise questions. For instance:</p><ul><li>Which suppliers in Europe provide electronic parts?</li><li>What products did Supplier B deliver last quarter?</li></ul><p>The graph understands structure and hierarchy. Because of the nodes and edges, it knows that “Supplier B” is related to certain purchase orders and that “Europe” contains Germany, France, etc.</p><h3 id="why-not-just-use-vectors">Why Not Just Use Vectors?</h3><p>Good question. Vector search engines like <a href="https://www.pinecone.io/?ref=blog.supermemory.ai">Pinecone</a> or <a href="https://weaviate.io/?ref=blog.supermemory.ai">Weaviate</a> are powerful for semantic matching. They shine when you’re dealing with natural language, fuzzy synonyms, or vague queries like “cheapest product with fast delivery.”</p><p>But they fall short when:</p><ul><li>You need exact business logic (“only suppliers who passed our compliance checks”).</li><li>You want explainability (how did the system decide this was the best answer?).</li><li>You care about relational context (“show suppliers that deliver Product X and are located in Germany”).</li></ul><p>With vector embeddings, the relationships between entities are implicit. With knowledge graphs, they’re explicit and that changes everything.</p><h3 id="how-knowledge-graphs-power-retrieval">How Knowledge Graphs Power Retrieval</h3><p>Imagine you get a user query like:<br>“Which suppliers in Europe provide lithium-ion batteries?”</p><p>A knowledge graph can:</p><ol><li>Identify "<strong>lithium-ion batteries</strong>" as a product.</li><li>Traverse the graph to find all suppliers linked to that product.</li><li>Filter by region to return only those with a located_in relationship pointing to European countries.</li></ol><p>And that’s not hypothetical. In the next section, you’ll build exactly that.</p><blockquote>Want to learn how memory improves LLM performance? <a href="https://supermemory.ai/blog/the-wow-factor-of-memory-how-flow-used-supermemory-to-build-smarter-stickier-products?ref=blog.supermemory.ai">See how Flow built smarter products with Supermemory</a></blockquote><p>By combining graphs and LLMs, you get the best of both worlds: structured, reliable facts with the flexibility of natural language understanding. It’s a big reason why memory-based platforms like <a href="https://supermemory.ai/?ref=blog.supermemory.ai">supermemory.ai</a> are designed to integrate with both vector and graph retrieval patterns.</p><h2 id="step-by-step-tutorial-supply-chain-qa-with-knowledge-graph-rag">Step-by-Step Tutorial: Supply Chain QA with Knowledge Graph RAG</h2><p>In this section, we will get practical. We will build a local knowledge graph using Neo4j, convert structured CSV fields into knowledge triples using GPT, query the graph to answer domain-specific questions and finally, generate a readable answer using a template.</p><h3 id="step-1-setup-and-install-dependencies">Step 1. Setup and Install Dependencies</h3><p>In this section, we will ensure that our local environment is ready for building and querying the Knowledge Graph.</p><p>We will need the following:</p><ul><li>Python 3.8+</li><li>Neo4j Desktop (<a href="https://neo4j.com/download/?ref=blog.supermemory.ai">Download it here</a>)</li><li>OpenAI account (for triple extraction)</li><li>Jupyter Notebook or any Python IDE (e.g., VS Code)</li><li><a href="https://www.kaggle.com/datasets/shahriarkabir/procurement-kpi-analysis-dataset?ref=blog.supermemory.ai">Procurement KPI Analysis Dataset</a></li></ul><p>Open your terminal or notebook and install the following:</p><pre><code class="language-python">pip install pandas py2neo openai neo4j datasets
</code></pre><p><code>py2neo</code> is the official library to work with Neo4j in Python, <code>openai</code> helps us make requests to the LLM, and <code>datasets</code> would let us download the Procurement KPI Analysis Dataset listed above.</p><h3 id="step-2-launch-neo4j">Step 2. Launch Neo4j</h3><p>This will prepare Neo4j to accept incoming connections and display the graph. Neo4j is a graph database, designed specifically to store and query data structured as <strong>nodes</strong> (entities) and <strong>edges</strong> (relationships). To run the Neo4j desktop locally, you can follow this step-by-step process:</p><h3 id="step-1-create-a-new-project">Step 1: Create a New Project</h3><ol><li>After this, you will find your local instance running. You’ll need the <strong>Connection URI</strong> for your Python app to connect. Click on your running DB, where you will be able to find the following:</li></ol><p>Create an instance, you can name it <strong>SupplyChainKG</strong>. Inside the instance, create a database user and send the password(you’ll use this in your code).<br></p><figure class="kg-card kg-image-card"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfpcVetsogbOWvfK6o7H3kUz6GckE_GPT9esEow35_IijSGcuE58yEkefcZF5sdxKjGyLe-QYcN3OyykkX1Xxkxcy857HhaXrs5aRaDNGKY-IpIwXrh9b47hWUMlVtqLOZGk7TY?key=lqZSFvuWmXmvGZnyQ5f1lQ" class="kg-image" alt="" loading="lazy" width="1600" height="1010"></figure><p>Open Neo4j Desktop<br></p><figure class="kg-card kg-image-card"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXd1LpvMZvsJy93yQeVaB7C6edgfa8Hw5jAh_TJU5zj46k71Q2I8lbZwKPBhkjPcL9mpuV_gGfxf1GO1TjNYLQ2SJt57luFf9G6FkTqL_xE8R3WX7DHXbVNNvWlVxMAMIQ6QlWtX?key=lqZSFvuWmXmvGZnyQ5f1lQ" class="kg-image" alt="" loading="lazy" width="1600" height="1010"></figure><ul><li>Connection URI: <code>neo4j://127.0.0.1:7687</code></li><li>Username: <code>neo4j</code></li><li>Password: whatever you set (e.g., test)</li></ul><figure class="kg-card kg-image-card"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXei76CYbLUsDo7n4r-VRXu1hGZwXIP9WL2LHX4k8o1wN9YjUGukujHAK2mQ5I1Q0RZ75LZWAWM222EJel8JTlcH7BgCwFh5Pb_r5lOy6_s9aUI8u9zPoqQMDeBJ4mSu_YpAzuaxdw?key=lqZSFvuWmXmvGZnyQ5f1lQ" class="kg-image" alt="" loading="lazy" width="1600" height="1010"></figure><h3 id="step-3-import-required-libraries-and-connect-to-neo4j">Step 3. Import Required Libraries and Connect to Neo4j</h3><p>Before we build the knowledge graph, we need to import the necessary libraries and connect to a local Neo4j database. Make sure Neo4j is running and your credentials are correct.</p><pre><code class="language-python">import ast 
from py2neo import Graph, Node, Relationship # To interact with Neo4j graph  
  
# Connect to your running Neo4j database instance  
graph = Graph("neo4j://localhost:7687", auth=("neo4j", "testpassword"))
</code></pre><p><code>ast</code> has been used for safely evaluating stringified list of tuples.</p><h3 id="step-4-define-the-graph-construction-function">Step 4. Define the Graph Construction Function</h3><p>Our app will work by using GPT to convert the rows in our dataset into strings of triples that we can use to construct nodes and relationships in the graph database. This function takes GPT's response (a string of triples), parses it, and constructs nodes and relationships inside the Neo4j graph.</p><p>Each triple is expected to follow the (subject, predicate, object) structure.</p><p>Declare a function in your file:</p><pre><code class="language-python">def build_graph_from_gpt_response(gpt_response):  
</code></pre><p>Use a try-catch block inside it to parse the GPT output:</p><pre><code class="language-python">	try:  
        # Safely parse the GPT response (which is a string of list of tuples)  
        triples = ast.literal_eval(gpt_response)  
    except Exception as e:  
        print("Parsing Error:", e)
</code></pre><p>Awesome, now let's extract the subject, predicate, and object from the GPT output and convert it to a graph as follows:</p><pre><code class="language-python">	for triple in triples:  
    # Ensure the triple is valid and contains exactly 3 items  
        if len(triple) != 3:  
            continue  
        # Strip and convert all parts to string (to avoid TypeErrors)  
        subject, predicate, obj = [str(x).strip() for x in triple]  
        
        # Create graph nodes for subject and object  
        subj_node = Node("Entity", name=subject)  
        obj_node = Node("Entity", name=obj)  
        
        # Create the relationship between the nodes  
        relationship = Relationship(subj_node, predicate, obj_node)  
        
        # Merge ensures no duplicates; updates if nodes/edges exist  
        graph.merge(subj_node, "Entity", "name")  
        graph.merge(obj_node, "Entity", "name")  
        graph.merge(relationship)
</code></pre><p>The loop only executes if the tuple has exactly 3 entities. Using the <code>strip()</code> function, the entites are extracted.</p><p>Nodes are constructed for the subject and object, wherease the predicate is used to create a relationship, and these are merged into the graph.</p><h3 id="step-5-import-openai-and-load-dataset">Step 5. Import OpenAI and Load Dataset</h3><p>We'll use the OpenAI API to extract structured knowledge from rows in the procurement CSV dataset. We’re using a <a href="https://www.kaggle.com/datasets/shahriarkabir/procurement-kpi-analysis-dataset?ref=blog.supermemory.ai">Procurement KPI Analysis Dataset</a> because it includes product, supplier, pricing, and compliance information.</p><pre><code class="language-python">import pandas as pd  
from openai import OpenAI # Ensure you've installed the OpenAI package  
  
# Initialize OpenAI client with your API key  
client = OpenAI(api_key="OPENAI_API_KEY")
  
# Load the Procurement KPI Analysis Dataset  
df = pd.read_csv("Procurement KPI Analysis Dataset.csv")
</code></pre><p>Initialize the OpenAI client with your OpenAI API Key and make sure you've downloaded the CSV from the link and stored it in the same folder as the file you're writing the code in.</p><h3 id="step-6-loop-over-a-few-rows-and-send-them-to-gpt">Step 6. Loop Over a Few Rows and Send Them to GPT</h3><p>We'll use GPT to extract <strong>subject-predicate-object</strong> triples from 3 sample rows in the dataset. Once you confirm that it's working, you can increase the number of rows.<br>Now we loop through a few rows of the dataset, construct a GPT prompt for each, extract triples, and pass them to the graph builder.</p><pre><code class="language-python">for i in range(5):  # Start with 5 rows
    row = df.iloc[i]
    
    # Clear prompt with structure and examples
    prompt = f"""
Extract subject-predicate-object triples from the following structured purchase order. Return the result as a valid Python list of 3-item tuples. Use proper literals — avoid vague terms like 'N/A'.

Example format:
[
  ("Delta Logistics", "supplies", "Raw Materials"),
  ("Raw Materials", "has_quantity", "1180"),
  ("Raw Materials", "has_price", "64.07")
]

Purchase Order:
Supplier: {row['Supplier']}
Item Category: {row['Item_Category']}
Quantity: {row['Quantity']}
Unit Price: {row['Unit_Price']}
Order Status: {row['Order_Status']}
Compliance: {row['Compliance']}

I need this to construct a knowledge graph from the data in the spreadsheet. Please ensure the triples are accurate and complete, reflecting the relationships in the purchase order.
"""

    # Send prompt to GPT
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        temperature=0
    )

    content = response.choices[0].message.content.strip()
    print(f"Triples for row {i}:", content)

    # Build graph from the returned triples
    build_graph_from_gpt_response(content)
</code></pre><p>You should get an output that looks like this:</p><figure class="kg-card kg-image-card"><img src="https://i.postimg.cc/85VXrwms/Screenshot-2025-07-12-at-09-40-45.png" class="kg-image" alt="" loading="lazy" width="1192" height="800"></figure><h3 id="step-7-querying-the-knowledge-graph-for-answers-rag">Step 7: Querying the Knowledge Graph for Answers (RAG)</h3><p>Now we test a natural language question: <em>"Which suppliers provide Raw Materials?"</em></p><p>Neo4J provides their own graph query language called Cypher which we'll use to run this natural language query as follows:</p><pre><code class="language-python">question_query = """
MATCH (s:Entity)-[:supplies]-&gt;(c:Entity {name: "Raw Materials"})
RETURN s.name AS supplier
"""

# Run the Cypher query
suppliers = graph.run(question_query).data()
print("Suppliers of Raw Materials:", suppliers)
</code></pre><p>Round brackets are used to represent <code>(:Nodes)</code> and <code>-[:ARROWS]-&gt;</code> represent relationships between the nodes. In the above query, we check for nodes that have the label "Entity", which supply to other nodes labelled "Entity" with the name "Raw Materials".</p><p>The output is as follows:</p><figure class="kg-card kg-image-card"><img src="https://i.postimg.cc/26bHJMjH/Screenshot-2025-07-12-at-09-59-58.png" class="kg-image" alt="" loading="lazy" width="968" height="48"></figure><h3 id="step-8-generate-a-natural-language-answer">Step 8: Generate a Natural Language Answer</h3><p>You can turn the Cypher output into human-readable text — a critical part of the RAG pipeline.</p><pre><code class="language-python">def format_answer(suppliers):
    if not suppliers:
        return "No compliant suppliers found for Raw Materials."
    names = [s["supplier"] for s in suppliers]
    return f"The following compliant suppliers provide Raw Materials: {', '.join(names)}."

# Print final answer
print(format_answer(suppliers))

</code></pre><p>The function simply access the array of objects that the graph returns, extracts the name of the supplier from it, and appends it to a string.</p><h3 id="step-9-visualizing-the-results-in-neo4j-desktop">Step 9. Visualizing the results in Neo4j Desktop</h3><p>Go to Neo4j Desktop and click on Query. Select your instance, and then run the queries in the text box provided.</p><p>First, let's check the number of nodes in our database with this query:</p><pre><code class="language-python">MATCH (n) RETURN COUNT(n);
</code></pre><p>Output:</p><figure class="kg-card kg-image-card"><img src="https://i.postimg.cc/3R5p8cCf/Screenshot-2025-07-12-at-10-07-19.png" class="kg-image" alt="" loading="lazy" width="1280" height="484"></figure><p>You should see a <strong>number &gt; 0</strong> in this case, we have <strong>21</strong></p><p>If you want to check for a sample of how the data is stored, run the following:</p><pre><code class="language-python">MATCH (a)-[r]-&gt;(b) RETURN a.name, type(r), b.name LIMIT 10;
</code></pre><p>Output:</p><figure class="kg-card kg-image-card"><img src="https://i.postimg.cc/brdqKzD7/Screenshot-2025-07-12-at-10-08-10.png" class="kg-image" alt="" loading="lazy" width="1033" height="800"></figure><p>To see the entire graph visualized: entities as circles, relationships as arrows, run this cypher:</p><pre><code class="language-python">MATCH (n)-[r]-&gt;(m) RETURN n, r, m LIMIT 100
</code></pre><figure class="kg-card kg-image-card"><img src="https://i.postimg.cc/sDQVmgRS/Screenshot-2025-07-12-at-10-08-54.png" class="kg-image" alt="" loading="lazy" width="1280" height="779"></figure><h2 id="how-do-you-measure-knowledge-graph-quality">How Do You Measure Knowledge Graph Quality?</h2><p>Building a knowledge graph is great. But how do you know if it’s actually any good?</p><p>This is where a lot of beginner AI engineers hit a wall. The graph looks fine, maybe even visualizes nicely in Neo4j, but under the hood, it could be missing key connections, introducing wrong relationships, or lacking coverage. And if you're plugging that graph into a retrieval-augmented generation (RAG) system, a weak graph means weak answers.</p><p>So let’s break down the core ways to evaluate the quality of your knowledge graph, especially the one we just built for the supply chain question-answering use case.</p><h3 id="coverage">Coverage</h3><p>Coverage refers to how much of the actual data your graph managed to capture in the form of nodes and edges. If your dataset contains 100 suppliers but only 40 show up as nodes in the graph, you're leaving insight on the table.</p><p>You can calculate this manually by comparing the number of entities/relations in your source data versus the ones that made it into the graph.</p><pre><code class="language-python"># Total number of unique suppliers in the CSV
total_suppliers = df['Supplier'].nunique()

# How many of those suppliers exist as named nodes in the graph?
query = """
MATCH (s:Entity)
WHERE EXISTS {
  MATCH (s)-[]-&gt;()
}
RETURN count(DISTINCT s.name) AS linked_suppliers
"""
linked_suppliers = graph.run(query, parameters={"supplier_list": df['Supplier'].dropna().unique().tolist()}).data()[0]['linked_suppliers']
coverage_percent = (linked_suppliers / total_suppliers) * 100

print(f"Supplier Node Coverage: {coverage_percent:.2f}%")
</code></pre><p>Why does this matter? Low coverage means your graph can’t support many types of queries, it limits what your app can answer.</p><h3 id="accuracy">Accuracy</h3><p>Accuracy means the relationships in the graph are actually correct. For instance, if “Delta Logistics” is shown supplying “Office Supplies” when they really supply “IT Equipment,” that’s a faulty edge.</p><p>To check for accuracy, spot-check your triples. A good practice is to manually review a subset of extracted triples and compare them with the original row in the dataset. If you’ve extracted 10 triples from GPT, verify if each subject-predicate-object makes sense contextually.</p><pre><code class="language-python">sample_check = graph.run("""  
MATCH (a:Entity)-[r]-&gt;(b:Entity)  
RETURN a.name AS subject, type(r) AS relation, b.name AS object  
LIMIT 10  
""").to_data_frame()  
  
print(sample_check)
</code></pre><h3 id="completeness">Completeness</h3><p>A graph can be accurate and still incomplete. Completeness checks whether all relevant connections were extracted and represented.</p><p>Checking this is trickier because it often involves domain knowledge. For example, if your business rule says every supplier must have a “compliance” rating, but your graph has some suppliers without any compliance edges, you’ve got gaps.</p><pre><code class="language-python"># Find suppliers without compliance links  
query = """  
MATCH (s:Entity)
WHERE NOT (s)-[:Compliance]-&gt;()
RETURN s.name AS MissingCompliance
"""  

missing_compliance = graph.run(query, parameters={"supplier_list": df['Supplier'].dropna().unique().tolist()}).to_data_frame()  
print(missing_compliance)

</code></pre><h3 id="explainability">Explainability</h3><p>One of the strongest benefits of knowledge graphs over vector search is explainability. Can you trace a clear path between entities? Can you see why a fact was returned?</p><p>To check for this, fire up <a href="https://neo4j.com/bloom/?ref=blog.supermemory.ai">Neo4j Bloom</a> and inspect the subgraphs visually. When you ask a question like “Which non-compliant suppliers provide raw materials?”, can you see the chain of edges that explain the result?</p><p>Alternatively, export a few subgraphs and explain them in plain English. That’s a human-readable test of graph logic.</p><p>You can get more scientific with:</p><ul><li>Precision &amp; Recall for named entity recognition (NER) and relation extraction (RE) stages — if your pipeline does this</li><li>Manual Subgraph Audits: Pick 10 nodes at random and audit their relationships</li><li>Consistency Checks: No dangling edges, no duplicate nodes with the same label, etc.</li></ul><p>If you want to go deeper, here are some tools that can be of help:</p><ul><li><a href="https://neo4j.com/bloom/?ref=blog.supermemory.ai">Neo4j Bloom</a>: Perfect for graph exploration without writing queries</li><li>Evaluation scripts: Write custom Python scripts that check for coverage, duplicate edges, or logical inconsistencies</li></ul><figure class="kg-card kg-image-card"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcXrUdHYzwlUesACSYBDl4PlcaD-kRkNfNvftzWQwF0FS2Ugel0OuYH4UQ2rVJFoZZYwrHFqVbu-bStHobh2aw9w9ONc5qgjLG4Qk0Zvmccgl2hZxEvDnew6x-HEJ3FC13_SVrUKA?key=lqZSFvuWmXmvGZnyQ5f1lQ" class="kg-image" alt="" loading="lazy" width="1536" height="1024"></figure><h2 id="how-good-is-the-knowledge-graph-we-built">How Good Is the Knowledge Graph We Built?</h2><p>Now that you've built our graph using Neo4j and GPT-generated triples, we can test it in real time. Using this code:</p><pre><code class="language-python"># What % of suppliers in CSV have at least one edge in the graph?  
total_suppliers = df['Supplier'].nunique()  
  
query = """  
MATCH (s:Entity)  
WHERE EXISTS {  
MATCH (s)-[]-&gt;()  
}  
RETURN count(DISTINCT s.name) AS linked_suppliers  
"""  
  
linked_suppliers = graph.run(query).data()[0]['linked_suppliers']  
coverage_percent = (linked_suppliers / total_suppliers) * 100  
  
print(f"Supplier Node Coverage: {coverage_percent:.2f}%")
</code></pre><p>Here is our result:</p><figure class="kg-card kg-image-card"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXf1gJP7Y99P8YxdapUn_kw1nmKxrOGHAXkbeSfr_KSihCEx7UHKDie1lfywCUPhhAAaK6zeFPR6pKjF1wFie9DZlH5F-gbwXUaLm-Rm8bI3s7eS0jZGrcbI2ZLhCiZX5wLnmNEn?key=lqZSFvuWmXmvGZnyQ5f1lQ" class="kg-image" alt="" loading="lazy" width="1544" height="100"></figure><p>If you’re getting low numbers, maybe GPT missed some triples or they weren’t added due to formatting errors, and that is your signal to iterate.</p><h2 id="conclusion">Conclusion</h2><p>Knowledge Graph RAG is a real-world solution when vector search alone doesn’t cut it. If you’ve ever struggled to answer structured questions or enforce logic across messy data, this combo brings sanity and structure to your pipeline.</p><p>And the best part? You don’t have to build it all from scratch.</p><p><a href="https://supermemory.ai/?ref=blog.supermemory.ai">Supermemory</a> gives you plug-and-play memory APIs that support both vector and graph-style retrieval, with built-in evaluation, flexible integrations, and long-term memory that scales. Whether you’re working with PDFs, emails, supply chains, or anything in between, it just works.</p><p>Ready to build smarter AI memory? <a href="https://supermemory.ai/docs/memory-api/introduction?ref=blog.supermemory.ai">Start here</a>.</p>
    </section>


</article>
</main>




            <aside class="read-more-wrap outer">
                <div class="read-more inner">
                        
<article class="post-card post keep-ratio">

    <a class="post-card-image-link" href="/blog/matryoshka-representation-learning-the-ultimate-guide-how-we-use-it/">

        <img class="post-card-image"
            srcset="/content/images/size/w300/2025/10/Matryoshka-Representation-Learning.png 300w,
                    /content/images/size/w600/2025/10/Matryoshka-Representation-Learning.png 600w,
                    /content/images/size/w1000/2025/10/Matryoshka-Representation-Learning.png 1000w,
                    /content/images/size/w2000/2025/10/Matryoshka-Representation-Learning.png 2000w"
            sizes="(max-width: 1000px) 400px, 800px"
            src="/blog/content/images/size/w600/2025/10/Matryoshka-Representation-Learning.png"
            alt="Matryoshka Representation Learning: The Ultimate Guide &amp; How We Use It"
            loading="lazy"
        />


    </a>

    <div class="post-card-content">

        <a class="post-card-content-link" href="/blog/matryoshka-representation-learning-the-ultimate-guide-how-we-use-it/">
            <header class="post-card-header">
                <div class="post-card-tags">
                </div>
                <h2 class="post-card-title">
                    Matryoshka Representation Learning: The Ultimate Guide &amp; How We Use It
                </h2>
            </header>
                <div class="post-card-excerpt">Embeddings are the cornerstone of any retrieval system. And the larger the embeddings, the more information they can store.

But large embeddings require a lot of memory, which leads to high computational costs and latency.

To reduce this high cost, we can use models that produce embeddings with small dimensions,</div>
        </a>

        <footer class="post-card-meta">
            <time class="post-card-meta-date" datetime="2025-10-19">19 Oct 2025</time>
                <span class="post-card-meta-length">8 min read</span>
        </footer>

    </div>

</article>
                        
<article class="post-card post keep-ratio">

    <a class="post-card-image-link" href="/blog/incident-report-october-18-2025-service-degradation/">

        <img class="post-card-image"
            srcset="/content/images/size/w300/2025/10/Frame-2147228224.png 300w,
                    /content/images/size/w600/2025/10/Frame-2147228224.png 600w,
                    /content/images/size/w1000/2025/10/Frame-2147228224.png 1000w,
                    /content/images/size/w2000/2025/10/Frame-2147228224.png 2000w"
            sizes="(max-width: 1000px) 400px, 800px"
            src="/blog/content/images/size/w600/2025/10/Frame-2147228224.png"
            alt="Incident Report: October 18, 2025 Service Degradation"
            loading="lazy"
        />


    </a>

    <div class="post-card-content">

        <a class="post-card-content-link" href="/blog/incident-report-october-18-2025-service-degradation/">
            <header class="post-card-header">
                <div class="post-card-tags">
                </div>
                <h2 class="post-card-title">
                    Incident Report: October 18, 2025 Service Degradation
                </h2>
            </header>
                <div class="post-card-excerpt">Summary

On October 18, between 1:17 PM and 1:45 PM PDT, we experienced service degradation that resulted in elevated API response times and some timeouts. This happened when two enterprise customers started major data backfills simultaneously— while we&#39;d planned for one, the second caught us by</div>
        </a>

        <footer class="post-card-meta">
            <time class="post-card-meta-date" datetime="2025-10-19">19 Oct 2025</time>
                <span class="post-card-meta-length">6 min read</span>
        </footer>

    </div>

</article>
                        
<article class="post-card post keep-ratio">

    <a class="post-card-image-link" href="/blog/how-to-make-your-mcp-clients-share-context-with-supermemory-mcp/">

        <img class="post-card-image"
            srcset="/content/images/size/w300/2025/10/18.png 300w,
                    /content/images/size/w600/2025/10/18.png 600w,
                    /content/images/size/w1000/2025/10/18.png 1000w,
                    /content/images/size/w2000/2025/10/18.png 2000w"
            sizes="(max-width: 1000px) 400px, 800px"
            src="/blog/content/images/size/w600/2025/10/18.png"
            alt="How To Make Your MCP Clients Share Context with Supermemory MCP"
            loading="lazy"
        />


    </a>

    <div class="post-card-content">

        <a class="post-card-content-link" href="/blog/how-to-make-your-mcp-clients-share-context-with-supermemory-mcp/">
            <header class="post-card-header">
                <div class="post-card-tags">
                </div>
                <h2 class="post-card-title">
                    How To Make Your MCP Clients Share Context with Supermemory MCP
                </h2>
            </header>
                <div class="post-card-excerpt">Let’s get practical here: have you ever dropped a PDF into Cursor, then pasted the same content into Claude just to “remind it”? Or tried to follow up on a thread, only to realize the memory lives in a different tool?

It’s annoying. It breaks your flow. And</div>
        </a>

        <footer class="post-card-meta">
            <time class="post-card-meta-date" datetime="2025-10-07">07 Oct 2025</time>
                <span class="post-card-meta-length">5 min read</span>
        </footer>

    </div>

</article>
                </div>
            </aside>



    </div>

    <footer class="site-footer outer">
        <div class="inner">
            <section class="copyright"><a href="https://supermemory.ai/blog">supermemory - Blog</a> &copy; 2025</section>
            <nav class="site-footer-nav">
                <ul class="nav">
    <li class="nav-sign-up"><a href="#/portal/">Sign up</a></li>
    <li class="nav-get-started"><a href="https://console.supermemory.ai">Get Started</a></li>
</ul>

            </nav>
            <div class="gh-powered-by"><a href="https://ghost.org/" target="_blank" rel="noopener">Powered by Ghost</a></div>
        </div>
    </footer>

</div>

    <div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">
    <div class="pswp__bg"></div>

    <div class="pswp__scroll-wrap">
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <div class="pswp__ui pswp__ui--hidden">
            <div class="pswp__top-bar">
                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
                <button class="pswp__button pswp__button--share" title="Share"></button>
                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>
        </div>
    </div>
</div>
<script
    src="https://code.jquery.com/jquery-3.5.1.min.js"
    integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0="
    crossorigin="anonymous">
</script>
<script src="/blog/assets/built/casper.js?v=259661198b"></script>
<script>
$(document).ready(function () {
    // Mobile Menu Trigger
    $('.gh-burger').click(function () {
        $('body').toggleClass('gh-head-open');
    });
    // FitVids - Makes video embeds responsive
    $(".gh-content").fitVids();
});
</script>

<script>
  // Change main logo link
  const mainLogo = document.querySelector('a.gh-head-logo');
  if (mainLogo) {
    mainLogo.href = "https://supermemory.ai/";
  }

  // Add "Get Started" button to gh-head-actions
  const actionsDiv = document.querySelector('div.gh-head-actions');
  if (actionsDiv) {
    const btn = document.createElement('a');
    btn.href = "https://console.supermemory.ai";
    btn.textContent = "Get Started";

    // Button styles
    btn.style.background = "#267BF1";
    btn.style.color = "#FFF";
    btn.style.padding = "1rem 2rem";
    btn.style.borderRadius = "6px";
    btn.style.fontWeight = "600";
    btn.style.textDecoration = "none";
    btn.style.fontSize = "1.6rem";
    btn.style.transition = "background 0.2s";
    btn.onmouseover = () => btn.style.background = "#1563c7";
    btn.onmouseout = () => btn.style.background = "#267BF1";

    actionsDiv.appendChild(btn);
  }
</script>

</body>
</html>
