<!DOCTYPE html>
<html lang="en" class="dark-mode">
<head>
<meta name="robots" content="index, follow">

    <title>How To Add Conversational Memory To LLMs Using LangChain</title>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    
    <link rel="preload" as="style" href="/blog/assets/built/screen.css?v=259661198b" />
    <link rel="preload" as="script" href="/blog/assets/built/casper.js?v=259661198b" />

    <link rel="stylesheet" type="text/css" href="/blog/assets/built/screen.css?v=259661198b" />

    <link rel="icon" href="https://supermemory.ai/blog/content/images/size/w256h256/2025/06/SuperM_LinkedIn-Github-Twitter_ProfilePicture--1--1.png" type="image/png">
    <link rel="canonical" href="https://supermemory.ai/blog/how-to-add-conversational-memory-to-llms-using-langchain/">
    <meta name="referrer" content="no-referrer-when-downgrade">
    
    <meta property="og:site_name" content="supermemory - Blog">
    <meta property="og:type" content="article">
    <meta property="og:title" content="How To Add Conversational Memory To LLMs Using LangChain">
    <meta property="og:description" content="Chatbots that don’t remember conversations are very frustrating to work with. Users treat AI like a human and expect it to remember.

LangChain recently migrated to LangGraph, a new stateful framework for building multi-step, memory-aware LLM apps. So while the docs might still say “LangChain memory,” what you’re">
    <meta property="og:url" content="https://supermemory.ai/blog/how-to-add-conversational-memory-to-llms-using-langchain/">
    <meta property="og:image" content="https://supermemory.ai/blog/content/images/2025/06/5.webp">
    <meta property="article:published_time" content="2025-06-19T02:45:00.000Z">
    <meta property="article:modified_time" content="2025-07-06T23:01:03.000Z">
    <meta property="article:tag" content="Learning">
    
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="How To Add Conversational Memory To LLMs Using LangChain">
    <meta name="twitter:description" content="Chatbots that don’t remember conversations are very frustrating to work with. Users treat AI like a human and expect it to remember.

LangChain recently migrated to LangGraph, a new stateful framework for building multi-step, memory-aware LLM apps. So while the docs might still say “LangChain memory,” what you’re">
    <meta name="twitter:url" content="https://supermemory.ai/blog/how-to-add-conversational-memory-to-llms-using-langchain/">
    <meta name="twitter:image" content="https://supermemory.ai/blog/content/images/2025/06/5.webp">
    <meta name="twitter:label1" content="Written by">
    <meta name="twitter:data1" content="Naman Bansal">
    <meta name="twitter:label2" content="Filed under">
    <meta name="twitter:data2" content="Learning">
    <meta name="twitter:site" content="@supermemoryai">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="675">
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "supermemory - Blog",
        "url": "https://supermemory.ai/blog/",
        "logo": {
            "@type": "ImageObject",
            "url": "https://supermemory.ai/blog/content/images/2025/06/Frame-2147223248.svg"
        }
    },
    "author": {
        "@type": "Person",
        "name": "Naman Bansal",
        "image": {
            "@type": "ImageObject",
            "url": "https://www.gravatar.com/avatar/1b424ffbaa308b371e62efa5919dfe3d?s=250&r=x&d=mp",
            "width": 250,
            "height": 250
        },
        "url": "https://supermemory.ai/blog/author/naman/",
        "sameAs": []
    },
    "headline": "How To Add Conversational Memory To LLMs Using LangChain",
    "url": "https://supermemory.ai/blog/how-to-add-conversational-memory-to-llms-using-langchain/",
    "datePublished": "2025-06-19T02:45:00.000Z",
    "dateModified": "2025-07-06T23:01:03.000Z",
    "image": {
        "@type": "ImageObject",
        "url": "https://supermemory.ai/blog/content/images/2025/06/5.webp",
        "width": 1200,
        "height": 675
    },
    "keywords": "Learning",
    "description": "Chatbots that don’t remember conversations are very frustrating to work with. Users treat AI like a human and expect it to remember.\n\nLangChain recently migrated to LangGraph, a new stateful framework for building multi-step, memory-aware LLM apps. So while the docs might still say “LangChain memory,” what you’re actually using under the hood is LangGraph.\n\nIn this guide, we’ll walk through how to implement short-term conversational memory in LangChain using LangGraph.\n\nWe’ll build a real-world ",
    "mainEntityOfPage": "https://supermemory.ai/blog/how-to-add-conversational-memory-to-llms-using-langchain/"
}
    </script>

    <meta name="generator" content="Ghost 5.130">
    <link rel="alternate" type="application/rss+xml" title="supermemory - Blog" href="https://supermemory.ai/blog/rss/">
    
    <script defer src="https://cdn.jsdelivr.net/ghost/sodo-search@~1.8/umd/sodo-search.min.js" data-key="d2a094c14f6148bdbd8ad26051" data-styles="https://cdn.jsdelivr.net/ghost/sodo-search@~1.8/umd/main.css" data-sodo-search="https://supermemory.ai/blog/" data-locale="en" crossorigin="anonymous"></script>
    
    <link href="https://supermemory.ai/blog/webmentions/receive/" rel="webmention">
    <script defer src="/blog/public/cards.min.js?v=259661198b"></script><style>:root {--ghost-accent-color: #3d49d8;}</style>
    <link rel="stylesheet" type="text/css" href="/blog/public/cards.min.css?v=259661198b">
    <style>
  .gh-footer-copyright {
    display: none !important;
}
a[href*="ghost.org"] {
    display: none !important;
}
::selection {
  background: #267BF1;
  color: #FFF;
}
</style>

<script>
document.addEventListener('DOMContentLoaded', function() {
    // Find all navigation logo links
    const logoLinks = document.querySelectorAll('.gh-navigation-logo');
    
    logoLinks.forEach(function(link) {
        // Change the href to point to main site
        link.href = 'https://supermemory.ai';
    });
});

  // Ensure all pages point to the main domain version
  const canonical = document.querySelector('link[rel="canonical"]');
  if (canonical && canonical.href.includes('blog.supermemory.ai')) {
    canonical.href = canonical.href.replace('blog.supermemory.ai', 'supermemory.ai/blog');
  }

if (typeof window !== 'undefined') {
  // Client-side check
  const hostname = window.location.hostname;
  const userAgent = navigator.userAgent;
  const isCloudflareWorker = userAgent.includes('Cloudflare-Workers');
  const isGhostAdmin = window.location.pathname.startsWith('/ghost');
  
  if (hostname === 'blog.supermemory.ai' && !isCloudflareWorker && !isGhostAdmin) {
    window.location.replace('https://supermemory.ai/blog' + window.location.pathname.replace('/blog', '') + window.location.search);
  }
}
</script>

<script>
    !function(t,e){var o,n,p,r;e.__SV||(window.posthog && window.posthog.__loaded)||(window.posthog=e,e._i=[],e.init=function(i,s,a){function g(t,e){var o=e.split(".");2==o.length&&(t=t[o[0]],e=o[1]),t[e]=function(){t.push([e].concat(Array.prototype.slice.call(arguments,0)))}}(p=t.createElement("script")).type="text/javascript",p.crossOrigin="anonymous",p.async=!0,p.src=s.api_host.replace(".i.posthog.com","-assets.i.posthog.com")+"/static/array.js",(r=t.getElementsByTagName("script")[0]).parentNode.insertBefore(p,r);var u=e;for(void 0!==a?u=e[a]=[]:a="posthog",u.people=u.people||[],u.toString=function(t){var e="posthog";return"posthog"!==a&&(e+="."+a),t||(e+=" (stub)"),e},u.people.toString=function(){return u.toString(1)+".people (stub)"},o="init Ce js Ls Te Fs Ds capture Ye calculateEventProperties zs register register_once register_for_session unregister unregister_for_session Ws getFeatureFlag getFeatureFlagPayload isFeatureEnabled reloadFeatureFlags updateEarlyAccessFeatureEnrollment getEarlyAccessFeatures on onFeatureFlags onSurveysLoaded onSessionId getSurveys getActiveMatchingSurveys renderSurvey displaySurvey canRenderSurvey canRenderSurveyAsync identify setPersonProperties group resetGroups setPersonPropertiesForFlags resetPersonPropertiesForFlags setGroupPropertiesForFlags resetGroupPropertiesForFlags reset get_distinct_id getGroups get_session_id get_session_replay_url alias set_config startSessionRecording stopSessionRecording sessionRecordingStarted captureException loadToolbar get_property getSessionProperty Bs Us createPersonProfile Hs Ms Gs opt_in_capturing opt_out_capturing has_opted_in_capturing has_opted_out_capturing get_explicit_consent_status is_capturing clear_opt_in_out_capturing Ns debug L qs getPageViewId captureTraceFeedback captureTraceMetric".split(" "),n=0;n<o.length;n++)g(u,o[n]);e._i.push([i,s,a])},e.__SV=1)}(document,window.posthog||[]);
    posthog.init('phc_9wkqAZtZYAUCNwvus0hYqcZbw5EBEX2s3QXjZoNdUNS', {
        api_host: 'https://us.i.posthog.com',
        defaults: '2025-05-24',
        person_profiles: 'identified_only', // or 'always' to create profiles for anonymous users as well
    })
</script>
    <link rel="preconnect" href="https://fonts.bunny.net"><link rel="stylesheet" href="https://fonts.bunny.net/css?family=space-grotesk:700|space-mono:400,700"><style>:root {--gh-font-heading: Space Grotesk;--gh-font-body: Space Mono;}</style>

</head>
<body class="post-template tag-learning gh-font-heading-space-grotesk gh-font-body-space-mono is-head-left-logo">
<div class="viewport">

    <header id="gh-head" class="gh-head outer">
        <div class="gh-head-inner inner">
            <div class="gh-head-brand">
                <a class="gh-head-logo" href="https://supermemory.ai/blog">
                        <img src="https://supermemory.ai/blog/content/images/2025/06/Frame-2147223248.svg" alt="supermemory - Blog">
                </a>
                <button class="gh-search gh-icon-btn" aria-label="Search this site" data-ghost-search><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2" width="20" height="20"><path stroke-linecap="round" stroke-linejoin="round" d="M21 21l-6-6m2-5a7 7 0 11-14 0 7 7 0 0114 0z"></path></svg></button>
                <button class="gh-burger" aria-label="Main Menu"></button>
            </div>

            <nav class="gh-head-menu">
                <ul class="nav">
    <li class="nav-home"><a href="https://supermemory.ai">Home</a></li>
    <li class="nav-blogs"><a href="https://supermemory.ai/blog">Blogs</a></li>
    <li class="nav-updates"><a href="https://docs.supermemory.ai/changelog/overview">Updates</a></li>
    <li class="nav-docs"><a href="https://docs.supermemory.ai">Docs</a></li>
</ul>

            </nav>

            <div class="gh-head-actions">
                        <button class="gh-search gh-icon-btn" aria-label="Search this site" data-ghost-search><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2" width="20" height="20"><path stroke-linecap="round" stroke-linejoin="round" d="M21 21l-6-6m2-5a7 7 0 11-14 0 7 7 0 0114 0z"></path></svg></button>
            </div>
        </div>
    </header>

    <div class="site-content">
        



<main id="site-main" class="site-main">
<article class="article post tag-learning ">

    <header class="article-header gh-canvas">

        <div class="article-tag post-card-tags">
                <span class="post-card-primary-tag">
                    <a href="/blog/tag/learning/">Learning</a>
                </span>
        </div>

        <h1 class="article-title">How To Add Conversational Memory To LLMs Using LangChain</h1>


        <div class="article-byline">
        <section class="article-byline-content">

            <ul class="author-list instapaper_ignore">
                <li class="author-list-item">
                    <a href="/blog/author/naman/" class="author-avatar" aria-label="Read more of Naman Bansal">
                        <img class="author-profile-image" src="https://www.gravatar.com/avatar/1b424ffbaa308b371e62efa5919dfe3d?s&#x3D;250&amp;r&#x3D;x&amp;d&#x3D;mp" alt="Naman Bansal" />
                    </a>
                </li>
            </ul>

            <div class="article-byline-meta">
                <h4 class="author-name"><a href="/blog/author/naman/">Naman Bansal</a></h4>
                <div class="byline-meta-content">
                    <time class="byline-meta-date" datetime="2025-06-19">19 Jun 2025</time>
                        <span class="byline-reading-time"><span class="bull">&bull;</span> 21 min read</span>
                </div>
            </div>

        </section>
        </div>

            <figure class="article-image">
                <img
                    srcset="/content/images/size/w300/2025/06/5.webp 300w,
                            /content/images/size/w600/2025/06/5.webp 600w,
                            /content/images/size/w1000/2025/06/5.webp 1000w,
                            /content/images/size/w2000/2025/06/5.webp 2000w"
                    sizes="(min-width: 1400px) 1400px, 92vw"
                    src="/blog/content/images/size/w2000/2025/06/5.webp"
                    alt="How To Add Conversational Memory To LLMs Using LangChain"
                />
            </figure>

    </header>

    <section class="gh-content gh-canvas">
        <p>Chatbots that don’t remember conversations are very frustrating to work with. Users treat AI like a human and expect it to remember.</p><p>LangChain recently migrated to<a href="https://langchain-ai.github.io/langgraph/?ref=blog.supermemory.ai"> <u>LangGraph</u></a>, a new stateful framework for building multi-step, memory-aware LLM apps. So while the docs might still say “LangChain memory,” what you’re actually using under the hood is LangGraph.</p><p>In this guide, we’ll walk through how to implement short-term conversational memory in LangChain using LangGraph.</p><p>We’ll build a real-world chatbot and compare the two core approaches to memory in LangGraph: message trimming and summarizing (more on them later). You’ll see how they differ, when to use what, and which one works best in a real use case.</p><p><strong>Note: </strong>Here’s <a href="https://github.com/namancoderpro/memory-chatbot?ref=blog.supermemory.ai"><u>the link to the GitHub repo</u></a> containing the code snippets used in the article.</p><p><strong>But here's the reality: while these techniques work for demos and simple use cases, they quickly break down when you need reliable, scalable memory for real applications.</strong></p><h2 id="the-use-case-a-therapy-chatbot-with-memory">The Use Case: A Therapy Chatbot With Memory</h2><p>To keep this practical, we’ll walk through a real-world example: a mental health chatbot. It’s the perfect use case to test memory, because:</p><ul><li>Conversations are long and personal</li><li>Users often revisit old topics or emotions</li><li>The bot needs to remember specific details like names, moods, and events</li></ul><p>We’ll use the same conversation flow across all memory types, so we can compare how each performs. By the end, you’ll know exactly how to add memory to your LangChain app and which memory type makes the most sense for your use case.</p><h2 id="primer-what-is-conversational-memory">Primer: What is Conversational Memory?</h2><p>Conversational memory allows chatbots to remember the context of their conversation with the user and tailor their answers to new prompts accordingly for a more intelligent experience.</p><p>It’s basically meant to model how you’d talk to another person. Imagine trying to hold an hour-long conversation with someone who keeps forgetting everything you’ve said. Not fun, right?</p><p>At an architectural level, memory in LLMs works like this:</p><ol><li><strong>Input and Output History</strong>: Every user message and model response is captured.</li><li><strong>Memory Storage</strong>: That conversation history is either:<ol><li>stored in the prompt window (ephemeral),</li><li>summarized and compressed (short-term memory), or</li><li>persisted in a separate, retrievable vector DB or external memory (long-term memory).</li></ol></li><li><strong>Retrieval Layer</strong>: At inference time, relevant pieces of past conversation are pulled in via raw replay, windowing, summarization, or vector similarity.</li><li><strong>Augmentation</strong>: That context is appended to the current prompt before sending to the LLM.</li></ol><figure class="kg-card kg-image-card"><img src="https://supermemory.ai/blog/content/images/2025/06/rep--1-.webp" class="kg-image" alt="" loading="lazy" width="2000" height="1125" srcset="https://supermemory.ai/blog/content/images/size/w600/2025/06/rep--1-.webp 600w, https://supermemory.ai/blog/content/images/size/w1000/2025/06/rep--1-.webp 1000w, https://supermemory.ai/blog/content/images/size/w1600/2025/06/rep--1-.webp 1600w, https://supermemory.ai/blog/content/images/size/w2400/2025/06/rep--1-.webp 2400w" sizes="(min-width: 720px) 720px"></figure><p>If we think of the most basic classification, then LLM memory can either be short-term or long-term. Here’s the difference:</p>
<!--kg-card-begin: html-->
<table style="border:none;border-collapse:collapse;"><colgroup><col width="99"><col width="202"><col width="162"><col width="161"></colgroup><tbody><tr style="height:25pt"><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;text-align: center;margin-top:12pt;margin-bottom:12pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Type</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;text-align: center;margin-top:12pt;margin-bottom:12pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">What It Does</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;text-align: center;margin-top:12pt;margin-bottom:12pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">How It’s Stored</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;text-align: center;margin-top:12pt;margin-bottom:12pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">When It’s Used</span></p></td></tr><tr style="height:39.25pt"><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;margin-top:12pt;margin-bottom:12pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Short-term</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;margin-top:12pt;margin-bottom:12pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Tracks the current conversation window</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;margin-top:12pt;margin-bottom:12pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Prompt buffer, summarization</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;margin-top:12pt;margin-bottom:12pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Most chatbot interactions</span></p></td></tr><tr style="height:39.25pt"><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;margin-top:12pt;margin-bottom:12pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Long-term</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;margin-top:12pt;margin-bottom:12pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Remembers facts and context across sessions</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;margin-top:12pt;margin-bottom:12pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Vector store, DBs, JSON, etc.</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;margin-top:12pt;margin-bottom:12pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Persistent user knowledge, histories</span></p></td></tr></tbody></table>
<!--kg-card-end: html-->
<p>While this architecture is clever, it's still fundamentally limited. Managing threads manually becomes a nightmare at scale, and the memory patterns are too rigid for complex, evolving user relationships.</p><h2 id="langgraph-memory-architecture-short-term-vs-long-term">LangGraph Memory Architecture: Short-Term vs Long-Term</h2><p>LangGraph introduces a new way of handling memory that’s far more powerful than the old ConversationBufferMemory-style classes you might be used to. It supports both short-term and long-term memory through state management and memory stores.</p><figure class="kg-card kg-image-card"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdDAWjG1VMPSSjc8NLe2mtrQYoheIyAr_In-26GbrpSfqMlnMC7heNmoJ-Uur1ZEE7nCdTyEtnd6n5FXZPQ4Rpy8hhLegIgI6xGW7D1ACkTsU3mSYLo_S9o5AxfurS6fgPzlygPbQ?key=D_xLASwNMHAmhwMRUaWFmA" class="kg-image" alt="" loading="lazy" width="624" height="201"></figure><p>LangGraph has a built-in persistence layer that allows it to remember what’s going on. It has a few key concepts like state, threads, and checkpoints.</p><p>Think of building a chatbot with LangGraph as writing in a notebook. The state refers to the notebook page where you're recording the actual conversation: what’s been said, what tools were used, what decisions were made.&nbsp;</p><p>Every time something happens in your app, this state, or notebook page, gets updated with what happened.</p><p>Now, imagine that every user, or session, gets their own notebook. That’s what a thread is: an isolated session that stores several different states and has a unique ID to identify it.&nbsp;</p><p>If a user returns tomorrow, you just give LangGraph the same thread ID, and it picks up right where you left off, flipping back to the last used page.</p><p>Now, let’s say you want to bookmark key moments in your notebook so you can return to them. That’s what checkpoints are: a snapshot of the state at a specific time.&nbsp;</p><p>LangGraph automatically creates a checkpoint every time you invoke a graph with a thread ID.</p><h3 id="how-langchain-implements-short-term-memory">How LangChain Implements Short-Term Memory</h3><p>You basically store the conversation history in the state, usually as a list of messages. Each time a user sends a message or the LLM generates a response, it is appended to this list, which is the short-term memory of the LLM. You can also store documents, uploaded files, and other metadata in the graph’s state so that the LLM has access to the full context.</p><p>There are two main ways to maintain this list of messages:</p><ul><li><strong>Message Buffering: </strong>Keeps the last <em>k </em>messages in memory</li><li><strong>Summarization: </strong>Replace older history with a summary</li></ul><figure class="kg-card kg-image-card"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcvy-TuEeVfx0DiSE5IRoNNz15qkoRL3vAmRBPzbuYxf2pWnue-XyRXIb9yjT-xeLVCLmXV6HXip5w3x4Ka5W9DFgBKelNa50L0a2jgb2XI2h8nckCzhxuqZe4UabQG3FJ_SNy2?key=D_xLASwNMHAmhwMRUaWFmA" class="kg-image" alt="" loading="lazy" width="594" height="200"></figure><p>Now, we’ll implement these in code for our therapy chatbot.</p><h2 id="adding-conversational-memory-to-our-llm">Adding Conversational Memory To Our LLM</h2><p>First, we’ll start by storing all the messages in our therapy chatbot’s context, and then we’ll move on to advanced techniques like message trimming and summarizing.</p><h3 id="basic-setup">Basic Setup</h3><p>Let’s start with the setup first. Create a directory for the chatbot and open it in your IDE:<br>
<br></p>
<pre><code class="language-bash">mkdir memory-chatbot
</code></pre>
<p>Install all the necessary Python libraries:<br>
<br></p>
<pre><code class="language-python">pip install --upgrade --quiet langchain langchain-openai langgraph
</code></pre>
<br>
<p><strong>Note:</strong> Use <code>pip3</code> in case just <code>pip</code> doesn’t work.</p>
<h3 id="basic-memory">Basic Memory</h3><p>Let’s start building the chatbot. Create a <code>file.py</code> file in your folder and import the necessary libraries:</p>
<br> 
<pre><code class="language-python">from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import StateGraph, START, MessagesState
import os
</code></pre>
<br> 
<p>You’ll start by setting your OpenAI API key as an environment variable. Navigate to your <code>memory-chatbot</code> folder and run the following command in the terminal to set the environment variable:</p>
<br> 
<pre><code class="language-bash">export OPENAI_API_KEY=”YOUR_API_KEY”
</code></pre>
<br> 
<p>Here are the steps to <a href="https://help.openai.com/en/articles/4936850-where-do-i-find-my-openai-api-key?ref=blog.supermemory.ai">find your OpenAI API key.</a></p>
<p>Back to <code>file.py</code>. Retrieve the environment variable:<br>
<br></p>
<pre><code class="language-python">os.environ.get("OPENAI_API_KEY")
</code></pre>
<br> 
<p>Now, initialize your model:<br>
<br></p>
<pre><code class="language-python">model = ChatOpenAI(model="gpt-4o-mini", temperature=0)
</code></pre>
<br> 
<p>The next step while building an LLM with LangGraph is to initialize the graph that represents the workflow that gets carried out. Here’s how:</p>
<br>
<pre><code class="language-python">builder = StateGraph(state_schema=MessagesState)
</code></pre>
<br> 
<p>Since the chatbot stores the chat history, this code defines <code>MessagesState</code> as the schema, which means the state contains a list of messages.</p>
<p>Now, if you think about it, graphs contain nodes that carry out the actual logic. Our main logic is going to be the chatbot that acts like a therapist, asks questions, generates responses, and stores them in its memory.</p>
<p>Thus, we’ll now define a function that carries out this logic as follows:</p>
<br>
<pre><code class="language-python">def chat_node(state: MessagesState):
&nbsp;&nbsp;&nbsp;system_message = SystemMessage(content="You're a kind therapy assistant.")
&nbsp;&nbsp;&nbsp;history = state["messages"]
&nbsp;&nbsp;&nbsp;prompt = [system_message] + history
&nbsp;&nbsp;&nbsp;response = model.invoke(prompt)
&nbsp;&nbsp;&nbsp;return {"messages": response}
</code></pre>
<br> 
<p>The node is passed the state, which is the chat history. Prompts to LLMs contain a system instruction (developer instructions on how the LLM must behave) and a human message.</p>
<p>The code instructs the LLM to act as a therapy assistant, and our prompt contains both the system message and the complete list of messages since we’re passing the entire context to it. This prompt is sent to OpenAI, which returns a response.</p>
<p>Let’s add this node to our graph and define it as the start node as follows:</p>
<br> 
<pre><code class="language-python">builder.add_node("chat", chat_node)
builder.add_edge(START, "chat")
</code></pre>
<br> 
<p>Next, write the following:</p>
<br> 
<pre><code class="language-python">memory = MemorySaver()
chat_app = builder.compile(checkpointer=memory)
</code></pre>
<br> 
<p>The <code>MemorySaver()</code> stores the state in memory, and the <code>builder.compile</code> compiles and executes the graph with the memory checkpointer.<br>
If you go back to our breakdown of LangChain’s architecture, you’ll remember that LangChain used a unique thread identifier to set a unique ID for each conversation and store its memory separately. Declare that in your code:</p>
<br> 
<pre><code class="language-python">thread_id = "1"
</code></pre>
<br> 
<p>Finally, let’s allow the user to enter messages and update our app’s state accordingly with the following code:<br>
<br></p>
<pre><code class="language-python">while True:
&nbsp;&nbsp;&nbsp;user_input = input("You: ")
&nbsp;&nbsp;&nbsp;state_update = {"messages": [HumanMessage(content=user_input)]}
&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;result = chat_app.invoke(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;state_update,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{"configurable": {"thread_id": thread_id}}
&nbsp;&nbsp;&nbsp;)
&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;print(result)
&nbsp;&nbsp;&nbsp;ai_msg = result["messages"][-1]
&nbsp;&nbsp;&nbsp;print("Bot:", ai_msg.content)
</code></pre>
<br>
<p>This code takes the user input, wraps it in the <code>HumanMessage</code> class, and appends the list of messages stored. After that, the graph is invoked with <code>chat_app.invoke</code>. The result is then printed.</p>
<p>Upon executing the code, we get the following results:</p>
<br> 
<pre><code class="language-bash">You: Hi I'm John from San Francisco
Bot: Hi John! It's nice to meet you. How are you doing today?
You : I'm doing okay, but I need some help managing my anxiety.Bot: I’m glad you reached out, John. Managing anxiety can be challenging, but there are strategies that can help. Can you share a bit more about what specifically triggers your anxiety or how it manifests for you?
</code></pre>
<br> 
<p>If we print the actual <code>messages</code> response, then we notice the following after the bot’s first response:</p>
<br> 
<pre><code class="language-bash">{'messages': [HumanMessage(content="Hi I'm John from San Francisco",...), AIMessage(content="Hi John! It's nice to meet you. How are you doing today?", …), HumanMessage(content="I'm doing okay, but I need some help managing my anxiety.", …), AIMessage(content='I’m glad you reached out, John. Managing anxiety can be challenging, but there are strategies that can help. Can you share a bit more about what specifically triggers your anxiety or how it manifests for you?', …)]}
</code></pre>
<p>What you can notice is that the <code>messages</code> key contains all the chats. The bot maintains a memory by storing all the previous chats and responding to new questions accordingly. Every time a question is asked, this entire list of messages is sent as part of the prompt.</p>
<p>This approach is pretty simple and gives us a workable chatbot, but it has some severe drawbacks. LangGraph replays all the messages stored in memory for every new message, and the full system prompt + message history is sent to the LLM as input.</p>
<p>LLMs have a finite token limit. Eventually, the prompt becomes too large to fit into the model’s context window, which leads to a shit ton of errors.</p>
<p>On top of that, more tokens = more cost = higher OpenAI bills. Our therapy chatbot would have long conversations, so that would become super expensive, super fast. Lastly, token-heavy prompts would also degrade performance.</p>
<p>That’s where the next approach comes in: message trimming.</p>
<h3 id="memory-with-message-trimming">Memory With Message Trimming</h3><p>Message trimming only stores a certain <code>k</code> number of messages in the memory, which prevents memory overload, stays within token limits, and focuses only on recent context.</p>
<p>To implement it, create a new file <code>trimmed.py</code> and add the following code to it:</p>
<pre><code class="language-python">from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import StateGraph, START, MessagesState
from langchain_core.messages import trim_messages
import os
os.environ.get("OPENAI_API_KEY")
# Initialize model
model = ChatOpenAI(model="gpt-4o-mini", temperature=0)
trimmer = trim_messages(strategy="last", max_tokens=2, token_counter=len)
# Create the graph
builder = StateGraph(state_schema=MessagesState)&nbsp;&nbsp;&nbsp;
def chat_node(state: MessagesState):
&nbsp;&nbsp;&nbsp;trimmed_messages = trimmer.invoke(state["messages"])
&nbsp;&nbsp;&nbsp;system_message = SystemMessage(content="You're a kind therapy assistant.")
&nbsp;&nbsp;&nbsp;prompt = [system_message] + trimmed_messages
&nbsp;&nbsp;&nbsp;response = model.invoke(prompt)
&nbsp;&nbsp;&nbsp;return {"messages": response}
builder.add_node("chat", chat_node)
builder.add_edge(START, "chat")
# Compile graph with MemorySaver
memory = MemorySaver()
chat_app = builder.compile(checkpointer=memory)
thread_id = "2"
while True:
&nbsp;&nbsp;&nbsp;user_input = input("You: ")
&nbsp;&nbsp;&nbsp;state_update = {"messages": [HumanMessage(content=user_input)]}
&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;result = chat_app.invoke(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;state_update,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{"configurable": {"thread_id": thread_id}}
&nbsp;&nbsp;&nbsp;)
&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;print(result)
&nbsp;&nbsp;&nbsp;ai_msg = result["messages"][-1]
&nbsp;&nbsp;&nbsp;print("Bot:", ai_msg.content)
</code></pre>
<p>You’ll notice most of this is the same as the previous file. Except, now we’re importing the <code>trim_messages</code> function:</p>
<pre><code class="language-python">from langchain_core.messages import trim_messages
</code></pre>
<p>And, we’re declaring a <code>trimmer</code> at the beginning of our code:</p>
<pre><code class="language-python">trimmer = trim_messages(strategy="last", max_tokens=10, token_counter=len)
</code></pre>
<p>This <code>trimmer</code> counts every message as 1 token, and only keeps the last 10 tokens (5 pairs of human + AI conversation).</p>
<p>The <code>chat_node</code> function has also been edited:<br>
<br></p>
<pre><code class="language-python">def chat_node(state: MessagesState):
&nbsp;&nbsp;&nbsp;trimmed_messages = trimmer.invoke(state["messages"])
&nbsp;&nbsp;&nbsp;system_message = SystemMessage(content="You're a kind therapy assistant.")
&nbsp;&nbsp;&nbsp;prompt = [system_message] + trimmed_messages
&nbsp;&nbsp;&nbsp;response = model.invoke(prompt)
&nbsp;&nbsp;&nbsp;return {"messages": response}
</code></pre>
<br>
<p>First, the messages are trimmed by invoking the trimmer on the current state, and then those trimmed messages are passed to the prompt. Thus, the entire state is not passed, saving tokens.</p>
<p>Now, if we replay our previous conversation, it goes as follows:</p>
<br>
<pre><code class="language-bash">You: hi im john from sf
Bot: Hi John! It's nice to meet you. How are you doing today?

You: im doing okay, you?&nbsp;&nbsp;
Bot: I’m glad to hear you’re doing okay! I’m here and ready to help with anything you need. Is there something specific on your mind today?

You: yeah dealing with some general anxiety
Bot: I’m sorry to hear that you’re feeling anxious. It’s completely normal to experience anxiety from time to time. Would you like to talk about what’s been causing your anxiety, or would you prefer some tips on managing it?

You: idk whats causing it - stressed about work i think
Bot: That makes sense. Work-related stress can definitely contribute to feelings of anxiety. It might help to break down what aspects of work are causing you stress. Is it the workload, deadlines, interactions with colleagues, or something else? Sometimes identifying specific triggers can make it easier to manage those feelings.

You: yeah i think it's a mix of them all&nbsp;&nbsp;
Bot: That sounds really overwhelming. It’s tough when multiple factors contribute to stress. Have you had a chance to take breaks or practice any self-care during busy times? Even small moments of relaxation can help alleviate some of that anxiety.

You: yeah i guess that makes sense. i should take a break right?
Bot: Absolutely! Taking a break can be really beneficial. It gives your mind a chance to reset and can help reduce feelings of anxiety. Even a short walk, some deep breathing exercises, or just stepping away from your workspace for a few minutes can make a difference. What do you think you might do for your break?

You: what's my name?
Bot: I’m sorry, but I don’t have access to personal information like your name unless you share it with me. If you’d like to tell me your name or anything else, feel free!
</code></pre>
<br>
<p>As you can see, when I ask the what’s my name question, the previous 5 memories don’t contain it, thus the chatbot forgets. It’s an improvement over the basic model, but it still has drawbacks:</p>
<ul>
<li>Trimming may lead to loss of crucial context, which is not a part of the last 10 tokens.</li>
<li>Trimming isn’t intelligent, so there’s an arbitrary information cutoff.</li>
<li>Even with trimming, token creep might happen if the input/output is extremely long.</li>
</ul>
<p>The next approach, summarization of old context, builds upon these.</p>
<h3 id="memory-with-summarization">Memory With Summarization</h3><figure class="kg-card kg-image-card"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXf_PdVuCaPCEO9h51RXhJXfkEdCMyt_Yn-fUVEFK9afS_hh_midNqAIgpcazIa8yW3c9nnK8BYqIUz-STFzAsCBcURLZztLH_hbdMFRW9WRQSWMuxCYS4yWAeTucgW074rnTx_Gew?key=D_xLASwNMHAmhwMRUaWFmA" class="kg-image" alt="" loading="lazy" width="609" height="242"></figure><p>Summarization allows the LLM to summarize all conversations before the current one, thus reducing token usage while also ensuring minimal context loss.</p>
<p>Create a new file <code>summarized.py</code> and write the following code in it:<br>
<br></p>
<pre><code class="language-python">from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage
from langchain_core.messages import RemoveMessage
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import StateGraph, START, MessagesState
import os
os.environ.get("OPENAI_API_KEY")
# Initialize model
model = ChatOpenAI(model="gpt-4o-mini", temperature=0)
# Create graph
builder = StateGraph(state_schema=MessagesState)&nbsp;&nbsp;&nbsp;
def chat_node(state: MessagesState):
&nbsp;&nbsp;&nbsp;system_message = SystemMessage(content="You're a kind therapy assistant.")
&nbsp;&nbsp;&nbsp;history = state["messages"][:-1]
&nbsp;&nbsp;&nbsp;if len(history) &gt;= 8:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;last_human_message = state["messages"][-1]
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;summary_prompt = (
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"Distill the above chat messages into a single summary message. "
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"Include as many specific details as you can."
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;summary_message = model.invoke(history + [HumanMessage(content=summary_prompt)])
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;delete_messages = [RemoveMessage(id=m.id) for m in state["messages"]]
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;human_message = HumanMessage(content=last_human_message.content)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;response = model.invoke([system_message, summary_message, human_message])
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;message_updates = [summary_message, human_message, response] + delete_messages
&nbsp;&nbsp;&nbsp;else:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;message_updates = model.invoke([system_message] + state["messages"])
&nbsp;&nbsp;&nbsp;return {"messages": message_updates}
builder.add_node("chat", chat_node)
builder.add_edge(START, "chat")
# Compile graph with MemorySaver
memory = MemorySaver()
chat_app = builder.compile(checkpointer=memory)
thread_id = "3"
while True:
&nbsp;&nbsp;&nbsp;user_input = input("You: ")
&nbsp;&nbsp;&nbsp;state_update = {"messages": [HumanMessage(content=user_input)]}
&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;result = chat_app.invoke(
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;state_update,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{"configurable": {"thread_id": thread_id}}
&nbsp;&nbsp;&nbsp;)
&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;print(result)
&nbsp;&nbsp;&nbsp;ai_msg = result["messages"][-1]
&nbsp;&nbsp;&nbsp;print("Bot:", ai_msg.content)
</code></pre>
<br> 
<p>This has some more significant changes. Firstly, you’re importing the <code>RemoveMessages</code> function, which wasn’t there previously.<br>
In terms of logic, there are changes in the <code>chat_node</code> function. The summarization logic only kicks in when the total conversation has gone over 8 messages.</p>
<p>If that happens, first the history is retrieved, except the latest HumanMessage, which is why we’ve used the [:-1] operator. Then, the model is invoked with a prompt to summarize the content, and the <code>history</code> variable is passed along with the instructions.</p>
<p>After that, all the summarized messages are removed from the state to save on tokens. The latest human message is wrapped again inside the <code>HumanMessage()</code> class, and then the model is invoked again with the summary and the human message, but this time with the therapy chatbot system message.</p>
<p>Finally, the model response is returned with the new information.<br>
If the history is less than 8 messages, then normal conversation chaining is used. This makes the chatbot efficient for shorter chats as well.</p>
<p>Upon running some test instructions, the following is seen:<br>
<br></p>
<pre><code class="language-bash">You: hi im jack from sf
Bot: Hi Jack! It's nice to meet you. How are you doing today?

You: im okay, wbu?
Bot: I’m doing well, thank you! I’m here to help you with anything you need. Is there something specific on your mind today?

You: just a bit of general anxiety
Bot: I’m sorry to hear that you’re feeling anxious. It’s completely normal to experience anxiety from time to time. Would you like to talk about what’s been causing your anxiety, or would you prefer some tips on how to manage it?

You: probably work is causing it
Bot: Work can definitely be a significant source of stress and anxiety. Would you like to share more about what aspects of work are making you feel anxious? Sometimes just talking about it can help.

You: yeah i think it's about how fast the deadlines are now
Bot: It sounds like the pressure of tight deadlines is really weighing on you. That can definitely contribute to feelings of anxiety. Would you like to talk about what specific aspects of the deadlines are causing you the most stress? Sometimes breaking it down can help us find ways to manage it better.
</code></pre>
<br> 
<p>The conversation flows as normal, however if you look at the full message output, after the 8 messages, we receive the following output in the console:<br>
<br></p>
<pre><code class="language-bash">{'messages': [AIMessage(content='**Jack from San Francisco mentioned he was feeling okay but experiencing some general anxiety, which he attributed to work-related stress. He expressed a desire to discuss the causes of his anxiety or seek tips for managing it.**',...), HumanMessage(content="yeah i think it's about how fast the deadlines are now",...), AIMessage(content='It sounds like the pressure of tight deadlines is really weighing on you. That can definitely contribute to feelings of anxiety. Would you like to talk about what specific aspects of the deadlines are causing you the most stress? Sometimes breaking it down can help us find ways to manage it better.', …)]}
</code></pre>
<p>As you’ll see, everything else from before was summarized, while the two latest messages are stored in memory. This is the best approach we’ve explored until now, but as always, there’s always room for improvement.</p>
<p>You see:</p>
<ul>
<li>Summaries are only as good as the prompt + model, so the quality’s a bit unreliable.</li>
<li>Hard deletes can be risky. If the summarization is off, you’ve lost the original data.</li>
</ul>
<h2 id="evaluating-both-the-techniques">Evaluating both the techniques</h2><p>For evaluation of the trimming and summarizing chatbots, we created 6 generic questions/responses we’d pass into the chatbots to see how they’d perform. We’re also measuring them across 6 quantitative metrics:</p>
<!--kg-card-begin: html-->
<table style="border:none;border-collapse:collapse;"><colgroup><col width="108"><col width="199"><col width="148"><col width="168"></colgroup><tbody><tr style="height:39.25pt"><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;text-align: center;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Metric</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;text-align: center;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Description</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;text-align: center;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Scoring (0–1)</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;text-align: center;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Notes</span></p></td></tr><tr style="height:52.75pt"><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Fact Retention</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Mentions or uses previous facts correctly (name, job, etc.)</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">1 = correct use; 0 = wrong/missing</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">-</span></p></td></tr><tr style="height:39.25pt"><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Entity Count</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Number of correctly named entities reused</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">0 to worse chatbot; 1 to the better one. If tied, 1 to both.</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Proxy for detail richness</span></p></td></tr><tr style="height:52.75pt"><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Latency / Turn Depth</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">How far back memory is used (e.g., Turn 1 fact used in Turn 6)</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">0 -1</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Higher is better</span></p></td></tr><tr style="height:39.25pt"><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Token Usage</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Total tokens used in the conversation</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">0 - 1</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Counted via OpenAI or LangSmith tools</span></p></td></tr><tr style="height:39.25pt"><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Response Length</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Average word/token count per AI reply</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">0 -1&nbsp;</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Spot unnecessarily long answers</span></p></td></tr><tr style="height:52.75pt"><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Repetition Penalty</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Counts of repeated generic phrases</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">-1 or 0</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Penalize fluff like “I understand how you feel.”</span></p></td></tr></tbody></table>
<!--kg-card-end: html-->
<p>Our 6 prompts are as follows:</p>
<!--kg-card-begin: html-->
<table style="border:none;border-collapse:collapse;"><colgroup><col width="384"></colgroup><tbody><tr style="height:25pt"><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><ul style="margin-top:0;margin-bottom:0;padding-inline-start:48px;"><li dir="ltr" style="list-style-type:disc;font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;" aria-level="1"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;" role="presentation"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">“Hi, I’m John. I’ve been feeling overwhelmed lately.”</span></p></li></ul></td></tr><tr style="height:39.25pt"><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><ul style="margin-top:0;margin-bottom:0;padding-inline-start:48px;"><li dir="ltr" style="list-style-type:disc;font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;" aria-level="1"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;" role="presentation"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">“It started after I got promoted to product manager..”</span></p></li></ul></td></tr><tr style="height:39.25pt"><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><ul style="margin-top:0;margin-bottom:0;padding-inline-start:48px;"><li dir="ltr" style="list-style-type:disc;font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;" aria-level="1"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;" role="presentation"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">“I usually go for a run in the morning, but I’ve stopped doing that recently.”</span></p></li></ul></td></tr><tr style="height:39.25pt"><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><ul style="margin-top:0;margin-bottom:0;padding-inline-start:48px;"><li dir="ltr" style="list-style-type:disc;font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;" aria-level="1"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;" role="presentation"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">“My therapist told me to start journaling, but I haven’t.”</span></p></li></ul></td></tr><tr style="height:25pt"><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><ul style="margin-top:0;margin-bottom:0;padding-inline-start:48px;"><li dir="ltr" style="list-style-type:disc;font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;" aria-level="1"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;" role="presentation"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">“Also, I had a fight with my brother Jack yesterday.”</span></p></li></ul></td></tr><tr style="height:39.25pt"><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><ul style="margin-top:0;margin-bottom:0;padding-inline-start:48px;"><li dir="ltr" style="list-style-type:disc;font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;" aria-level="1"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;" role="presentation"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">“Can you help me make a plan to feel more in control again?”</span></p></li></ul></td></tr></tbody></table>
<!--kg-card-end: html-->
<h3 id="trimming-set-at-8-tokens">Trimming (set at 8 tokens)</h3><pre><code class="language-bash">You: “Hi, I’m John. I’ve been feeling overwhelmed lately.”
Bot: Hi John, it’s great to meet you. I’m really sorry to hear that you’ve been feeling overwhelmed. Would you like to share a bit more about what’s been going on? Sometimes talking about it can help.

You: “It started after I got promoted to product manager..”
Bot: That sounds like a big change, John. Congratulations on your promotion! It’s understandable to feel overwhelmed with new responsibilities. What aspects of your new role are feeling particularly challenging for you?

You: “I usually go for a run in the morning, but I’ve stopped doing that recently.”
Bot: It sounds like running has been an important part of your routine. Exercise can be a great way to manage stress and clear your mind. What do you think has made it difficult for you to keep up with your morning runs lately?

You: “My therapist told me to start journaling, but I haven’t.”
Bot: It’s okay, John. Starting something new like journaling can be tough, especially when you’re feeling overwhelmed. Sometimes it helps to set small, manageable goals. Would you be open to trying just a few minutes of journaling each day, or even just jotting down a few thoughts when you feel up to it? It can be a great way to process your feelings.

You: “Also, I had a fight with my brother Jack yesterday.”
Bot: I’m sorry to hear that, John. Conflicts with family can be really tough to navigate. Would you like to talk about what happened with Jack? Sometimes discussing the situation can help you find some clarity or a way to approach it.

You: “Can you help me make a plan to feel more in control again?”
Bot: Absolutely, John. It’s great that you want to take steps to feel more in control. Here’s a simple plan we can start with:
1. **Set Small Goals**: Choose one or two small, achievable goals each week. For example, you might aim to go for a short run a couple of times or write in your journal for just five minutes.
2. **Establish a Routine**: Try to create a daily routine that includes time for exercise, journaling, and some relaxation. Consistency can help you feel more grounded.
3. **Communicate with Jack**: If you feel ready, consider reaching out to your brother to talk about the fight. A calm conversation can help clear the air and strengthen your relationship.
4. **Practice Mindfulness**: Incorporate a few minutes of mindfulness or deep breathing into your day. This can help reduce stress and bring you back to the present moment.
5. **Reflect Weekly**: At the end of each week, take a moment to reflect on what went well and what you might want to adjust for the following week.
How does that sound to you? Would you like to modify any part of this plan?
</code></pre>
<p>Tokens used: 1.618K completion tokens</p><h3 id="summarizing-set-at-8-messages">Summarizing (set at 8 messages)</h3><p>Here’s how it responded:</p><pre><code class="language-bash">You: “Hi, I’m John. I’ve been feeling overwhelmed lately.”
Bot: Hi John, it’s nice to meet you. I’m really glad you reached out. Feeling overwhelmed can be tough to deal with. Would you like to share more about what’s been on your mind or what’s been making you feel this way?

You: “It started after I got promoted to product manager..”
Bot: That sounds like a significant change, John. Congratulations on your promotion! It’s understandable to feel overwhelmed with new responsibilities. What aspects of your new role are feeling particularly challenging for you?

You: “I usually go for a run in the morning, but I’ve stopped doing that recently.”
Bot: It sounds like running was an important part of your routine and a way for you to manage stress. It’s common for changes in our lives, like a new job, to disrupt our usual habits. How do you feel about not being able to run lately? Do you think getting back to it might help you feel a bit better?

You: “My therapist told me to start journaling, but I haven’t.”
Bot: Journaling can be a really helpful tool for processing your thoughts and feelings, but it can be hard to get started, especially when you’re feeling overwhelmed. It’s okay if you haven’t begun yet. Maybe you could start with just a few minutes a day or even jot down a few thoughts when you feel inspired. What do you think might help you get started with journaling?

You: “Also, I had a fight with my brother Jack yesterday.”
Bot: I'm sorry to hear that you had a fight with your brother, Jack. Conflicts with loved ones can be really tough to navigate. How are you feeling about the situation? Do you want to talk about what happened? Sometimes expressing your thoughts and feelings can help you process the experience.

You: “Can you help me make a plan to feel more in control again?”
Bot: Absolutely, I’d be happy to help you create a plan to feel more in control. Here’s a simple outline you can follow:
1. **Reintroduce Morning Runs:**
&nbsp;&nbsp;&nbsp;- **Set a Schedule:** Choose specific days and times for your runs. Start with two or three days a week.
&nbsp;&nbsp;&nbsp;- **Start Small:** If you’re feeling overwhelmed, begin with shorter runs or even brisk walks to ease back into it.
2. **Begin Journaling:**
&nbsp;&nbsp;&nbsp;- **Set Aside Time:** Dedicate a few minutes each day, perhaps in the morning or before bed, to write down your thoughts and feelings.
&nbsp;&nbsp;&nbsp;- **Prompts:** If you’re unsure what to write about, consider prompts like “What am I grateful for today?” or “What challenges did I face, and how did I handle them?”
3. **Address the Conflict with Jack:**
&nbsp;&nbsp;&nbsp;- **Reflect:** Take some time to think about what led to the fight and how you feel about it.
&nbsp;&nbsp;&nbsp;- **Communicate:** When you feel ready, consider reaching out to Jack to talk about what happened. Express your feelings and listen to his perspective.
4. **Practice Mindfulness:**
&nbsp;&nbsp;&nbsp;- **Breathing Exercises:** Incorporate deep breathing or meditation into your daily routine to help manage stress.
&nbsp;&nbsp;&nbsp;- **Mindful Moments:** Take a few moments throughout the day to check in with yourself and acknowledge your feelings.
5. **Set Realistic Goals:**
&nbsp;&nbsp;&nbsp;- **Daily Goals:** Identify one or two small goals each day that can help you feel accomplished, whether it’s going for a run, journaling, or reaching out to a friend.
6. **Seek Support:**
&nbsp;&nbsp;&nbsp;- **Talk to Someone:** Whether it’s a friend, family member, or therapist, sharing your feelings can provide relief and perspective.
How does this plan sound to you? Would you like to adjust anything or add more specific details?
</code></pre>
<p>Tokens used: 1,940 tokens</p><p>Evaluation:</p>
<!--kg-card-begin: html-->
<table style="border:none;border-collapse:collapse;"><colgroup><col width="92"><col width="129"><col width="79"><col width="114"><col width="210"></colgroup><tbody><tr style="height:25pt"><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;text-align: center;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Metric</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;text-align: center;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Description</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;text-align: center;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Trimming</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;text-align: center;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Summarization</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;text-align: center;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Notes</span></p></td></tr><tr style="height:67pt"><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Fact Retention</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Correct recall/use of facts from earlier turns</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">1</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">1</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Both bots correctly referenced all six facts (John, promotion, running, journaling, Jack, and feeling overwhelmed).</span></p></td></tr><tr style="height:67pt"><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Entity Count</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Number of correctly named entities reused</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">1</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">1</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Both mentioned John, Jack, running, journaling, etc. Summarization didn’t sacrifice detail.</span></p></td></tr><tr style="height:67pt"><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Latency / Turn Depth</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">How far back a memory is reused (e.g., Turn 1 info in Turn 6)</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">0</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">1</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Summarization reused context from all 5 previous turns in the final response, trimming lost older context earlier.</span></p></td></tr><tr style="height:80.5pt"><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Token Usage</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Total tokens used</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">1</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">0</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Trimming uses fewer tokens due to shorter prompts and hard message cuts; summarization adds summarizer calls and more verbose responses.</span></p></td></tr><tr style="height:80.5pt"><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Avg. Response Length</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Average length of bot replies</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">1</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">0</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Trimming’s responses are shorter, while summarization is more verbose; it can be less desirable for token-sensitive applications.</span></p></td></tr><tr style="height:80.5pt"><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:700;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Repetition Penalty</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Penalty for repeated generic phrases (lower = better)</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">-1</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">0</span></p></td><td style="border-left:solid #ffffff 1pt;border-right:solid #ffffff 1pt;border-bottom:solid #ffffff 1pt;border-top:solid #ffffff 1pt;vertical-align:top;padding:5pt 5pt 5pt 5pt;overflow:hidden;overflow-wrap:break-word;"><p dir="ltr" style="line-height:1.2;margin-top:0pt;margin-bottom:0pt;"><span style="font-size:12pt;font-family:Arial,sans-serif;color:#ffffff;background-color:transparent;font-weight:400;font-style:normal;font-variant:normal;text-decoration:none;vertical-align:baseline;white-space:pre;white-space:pre-wrap;">Trimming led to more generic fallback lines (“That’s understandable.”); summarization preserved specificity despite verbosity.</span></p></td></tr></tbody></table>
<!--kg-card-end: html-->
<p>Final scores are 3-3 for both models, tied. While both trimming and summarization scored equally in our evaluation, the tie doesn’t imply that the two strategies are interchangeable.</p><p>Trimming excels in token economy and snappy responses. It’s simple, lightweight, and great for short or transactional conversations. But once the dialogue gets deeper or longer, it starts forgetting context, leading to generic or disconnected replies, which earns it a repetition penalty.</p><p>Summarization, on the other hand, maintains coherent long-form memory. It preserves emotional and factual continuity over time, allowing for more natural conversations. But this comes at a cost: higher token usage and longer responses, which might not be ideal for production environments with strict token budgets.</p><h2 id="supermemory">Supermemory</h2><p>With Supermemory, you can add memory with just one line of code.</p><pre><code class="language-javascript">import OpenAI from "openai"

const client = new OpenAI({  
  baseUrl: "https://api.supermemory.ai/v3/https://api.openai.com/v1/"
}, {
  headers: {
    "x-supermemory-user-id": "dhravya"
    }
})</code></pre><p>That's it.</p><p>Supermemory automatically ingests and manages the context, using a combination of Graphs and Vector store. Read more about it in this blog - <a href="https://supermemory.ai/blog/memory-engine/?ref=blog.supermemory.ai">https://supermemory.ai/blog/memory-engine/</a></p><h2 id="conclusion">Conclusion</h2><p>This article covered everything from how conversational memory works to implementing it in LangChain, using both trimming and summarizing, and then evaluating them for their particular use cases.</p><p>However, it starts to fall apart as complexity grows. <strong>If you're building apps and AI agents that need to remember across sessions, adapt to users, or scale without manual patchwork, Supermemory's Memory API might be a better solution for you. Check it out </strong><a href="http://supermemory.ai/?ref=blog.supermemory.ai"><strong><u>here.</u></strong></a></p><p></p>
    </section>


</article>
</main>




            <aside class="read-more-wrap outer">
                <div class="read-more inner">
                        
<article class="post-card post keep-ratio">

    <a class="post-card-image-link" href="/blog/matryoshka-representation-learning-the-ultimate-guide-how-we-use-it/">

        <img class="post-card-image"
            srcset="/content/images/size/w300/2025/10/Matryoshka-Representation-Learning.png 300w,
                    /content/images/size/w600/2025/10/Matryoshka-Representation-Learning.png 600w,
                    /content/images/size/w1000/2025/10/Matryoshka-Representation-Learning.png 1000w,
                    /content/images/size/w2000/2025/10/Matryoshka-Representation-Learning.png 2000w"
            sizes="(max-width: 1000px) 400px, 800px"
            src="/blog/content/images/size/w600/2025/10/Matryoshka-Representation-Learning.png"
            alt="Matryoshka Representation Learning: The Ultimate Guide &amp; How We Use It"
            loading="lazy"
        />


    </a>

    <div class="post-card-content">

        <a class="post-card-content-link" href="/blog/matryoshka-representation-learning-the-ultimate-guide-how-we-use-it/">
            <header class="post-card-header">
                <div class="post-card-tags">
                </div>
                <h2 class="post-card-title">
                    Matryoshka Representation Learning: The Ultimate Guide &amp; How We Use It
                </h2>
            </header>
                <div class="post-card-excerpt">Embeddings are the cornerstone of any retrieval system. And the larger the embeddings, the more information they can store.

But large embeddings require a lot of memory, which leads to high computational costs and latency.

To reduce this high cost, we can use models that produce embeddings with small dimensions,</div>
        </a>

        <footer class="post-card-meta">
            <time class="post-card-meta-date" datetime="2025-10-19">19 Oct 2025</time>
                <span class="post-card-meta-length">8 min read</span>
        </footer>

    </div>

</article>
                        
<article class="post-card post keep-ratio">

    <a class="post-card-image-link" href="/blog/incident-report-october-18-2025-service-degradation/">

        <img class="post-card-image"
            srcset="/content/images/size/w300/2025/10/Frame-2147228224.png 300w,
                    /content/images/size/w600/2025/10/Frame-2147228224.png 600w,
                    /content/images/size/w1000/2025/10/Frame-2147228224.png 1000w,
                    /content/images/size/w2000/2025/10/Frame-2147228224.png 2000w"
            sizes="(max-width: 1000px) 400px, 800px"
            src="/blog/content/images/size/w600/2025/10/Frame-2147228224.png"
            alt="Incident Report: October 18, 2025 Service Degradation"
            loading="lazy"
        />


    </a>

    <div class="post-card-content">

        <a class="post-card-content-link" href="/blog/incident-report-october-18-2025-service-degradation/">
            <header class="post-card-header">
                <div class="post-card-tags">
                </div>
                <h2 class="post-card-title">
                    Incident Report: October 18, 2025 Service Degradation
                </h2>
            </header>
                <div class="post-card-excerpt">Summary

On October 18, between 1:17 PM and 1:45 PM PDT, we experienced service degradation that resulted in elevated API response times and some timeouts. This happened when two enterprise customers started major data backfills simultaneously— while we&#39;d planned for one, the second caught us by</div>
        </a>

        <footer class="post-card-meta">
            <time class="post-card-meta-date" datetime="2025-10-19">19 Oct 2025</time>
                <span class="post-card-meta-length">6 min read</span>
        </footer>

    </div>

</article>
                        
<article class="post-card post keep-ratio">

    <a class="post-card-image-link" href="/blog/how-to-make-your-mcp-clients-share-context-with-supermemory-mcp/">

        <img class="post-card-image"
            srcset="/content/images/size/w300/2025/10/18.png 300w,
                    /content/images/size/w600/2025/10/18.png 600w,
                    /content/images/size/w1000/2025/10/18.png 1000w,
                    /content/images/size/w2000/2025/10/18.png 2000w"
            sizes="(max-width: 1000px) 400px, 800px"
            src="/blog/content/images/size/w600/2025/10/18.png"
            alt="How To Make Your MCP Clients Share Context with Supermemory MCP"
            loading="lazy"
        />


    </a>

    <div class="post-card-content">

        <a class="post-card-content-link" href="/blog/how-to-make-your-mcp-clients-share-context-with-supermemory-mcp/">
            <header class="post-card-header">
                <div class="post-card-tags">
                </div>
                <h2 class="post-card-title">
                    How To Make Your MCP Clients Share Context with Supermemory MCP
                </h2>
            </header>
                <div class="post-card-excerpt">Let’s get practical here: have you ever dropped a PDF into Cursor, then pasted the same content into Claude just to “remind it”? Or tried to follow up on a thread, only to realize the memory lives in a different tool?

It’s annoying. It breaks your flow. And</div>
        </a>

        <footer class="post-card-meta">
            <time class="post-card-meta-date" datetime="2025-10-07">07 Oct 2025</time>
                <span class="post-card-meta-length">5 min read</span>
        </footer>

    </div>

</article>
                </div>
            </aside>



    </div>

    <footer class="site-footer outer">
        <div class="inner">
            <section class="copyright"><a href="https://supermemory.ai/blog">supermemory - Blog</a> &copy; 2025</section>
            <nav class="site-footer-nav">
                <ul class="nav">
    <li class="nav-sign-up"><a href="#/portal/">Sign up</a></li>
    <li class="nav-get-started"><a href="https://console.supermemory.ai">Get Started</a></li>
</ul>

            </nav>
            <div class="gh-powered-by"><a href="https://ghost.org/" target="_blank" rel="noopener">Powered by Ghost</a></div>
        </div>
    </footer>

</div>

    <div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">
    <div class="pswp__bg"></div>

    <div class="pswp__scroll-wrap">
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <div class="pswp__ui pswp__ui--hidden">
            <div class="pswp__top-bar">
                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
                <button class="pswp__button pswp__button--share" title="Share"></button>
                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>
        </div>
    </div>
</div>
<script
    src="https://code.jquery.com/jquery-3.5.1.min.js"
    integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0="
    crossorigin="anonymous">
</script>
<script src="/blog/assets/built/casper.js?v=259661198b"></script>
<script>
$(document).ready(function () {
    // Mobile Menu Trigger
    $('.gh-burger').click(function () {
        $('body').toggleClass('gh-head-open');
    });
    // FitVids - Makes video embeds responsive
    $(".gh-content").fitVids();
});
</script>

<script>
  // Change main logo link
  const mainLogo = document.querySelector('a.gh-head-logo');
  if (mainLogo) {
    mainLogo.href = "https://supermemory.ai/";
  }

  // Add "Get Started" button to gh-head-actions
  const actionsDiv = document.querySelector('div.gh-head-actions');
  if (actionsDiv) {
    const btn = document.createElement('a');
    btn.href = "https://console.supermemory.ai";
    btn.textContent = "Get Started";

    // Button styles
    btn.style.background = "#267BF1";
    btn.style.color = "#FFF";
    btn.style.padding = "1rem 2rem";
    btn.style.borderRadius = "6px";
    btn.style.fontWeight = "600";
    btn.style.textDecoration = "none";
    btn.style.fontSize = "1.6rem";
    btn.style.transition = "background 0.2s";
    btn.onmouseover = () => btn.style.background = "#1563c7";
    btn.onmouseout = () => btn.style.background = "#267BF1";

    actionsDiv.appendChild(btn);
  }
</script>

</body>
</html>
